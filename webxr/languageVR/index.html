<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>WebXR Language Practice VR (Quest Compatible)</title>
    <meta name="description" content="Learn languages in VR with Vosk offline speech recognition">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://aframe.io/releases/1.7.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v7.2.0/dist/aframe-extras.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.173.0/examples/js/loaders/FBXLoader.js"></script>
    <!-- Vosk.js for Quest compatibility -->
    <script src="https://cdn.jsdelivr.net/npm/vosk-browser@0.0.8/dist/vosk.js"></script>
    <style>
      body { margin: 0; overflow: hidden; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
      
      /* Desktop UI */
      #ui {
        position: fixed; top: 10px; left: 10px;
        background: rgba(0, 0, 0, 0.9); color: white;
        padding: 20px; border-radius: 10px;
        font-family: 'Segoe UI', sans-serif;
        z-index: 1000; max-width: 400px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
      }
      #ui h2 { margin: 0 0 15px 0; color: #4CAF50; font-size: 24px; }
      #ui h3 { margin: 15px 0 10px 0; color: #81C784; font-size: 18px; }
      
      .status { font-size: 12px; color: #888; margin: 5px 0; }
      .status.active { color: #4CAF50; }
      .status.error { color: #f44336; }
      
      .language-selector {
        display: flex; gap: 10px; margin: 15px 0;
      }
      
      .lang-btn {
        padding: 10px 15px; background: #2196F3; border: none;
        color: white; border-radius: 5px; cursor: pointer;
        font-size: 14px; transition: all 0.3s;
      }
      .lang-btn:hover { background: #1976D2; transform: scale(1.05); }
      .lang-btn.active { background: #4CAF50; }
      
      .scenario-list {
        display: flex; flex-direction: column; gap: 8px; margin: 10px 0;
      }
      
      .scenario-btn {
        padding: 12px; background: #424242; border: none;
        color: white; border-radius: 5px; cursor: pointer;
        text-align: left; transition: all 0.3s;
        border-left: 4px solid #2196F3;
      }
      .scenario-btn:hover { background: #616161; transform: translateX(5px); }
      .scenario-btn.active { background: #1976D2; border-left-color: #4CAF50; }
      
      #score {
        font-size: 20px; color: #FFD700; font-weight: bold;
        margin: 10px 0; padding: 10px; background: rgba(255, 215, 0, 0.1);
        border-radius: 5px; text-align: center;
      }
      
      .info { 
        font-size: 11px; color: #999; margin-top: 15px; 
        padding-top: 15px; border-top: 1px solid #333;
        line-height: 1.6;
      }
      
      #feedback-banner {
        position: fixed; top: 50%; left: 50%;
        transform: translate(-50%, -50%) scale(0);
        background: rgba(76, 175, 80, 0.95);
        color: white; padding: 30px 50px;
        border-radius: 15px; font-size: 32px;
        font-weight: bold; z-index: 2000;
        transition: transform 0.3s cubic-bezier(0.68, -0.55, 0.265, 1.55);
        box-shadow: 0 8px 30px rgba(0, 0, 0, 0.5);
        text-align: center;
      }
      
      #feedback-banner.show { transform: translate(-50%, -50%) scale(1); }
      #feedback-banner.success { background: rgba(76, 175, 80, 0.95); }
      #feedback-banner.warning { background: rgba(255, 152, 0, 0.95); }
      #feedback-banner.error { background: rgba(244, 67, 54, 0.95); }
      
      #current-phrase {
        position: fixed; top: 20px; left: 50%;
        transform: translateX(-50%);
        background: rgba(0, 0, 0, 0.85); color: white;
        padding: 20px 40px; border-radius: 10px;
        font-size: 24px; z-index: 1500;
        text-align: center; max-width: 600px;
        display: none;
      }
      
      #current-phrase.active { display: block; }
      
      #translation {
        font-size: 16px; color: #81C784;
        margin-top: 10px; font-style: italic;
      }
      
      .mic-indicator {
        display: inline-block;
        width: 12px; height: 12px;
        background: #f44336;
        border-radius: 50%;
        margin-right: 8px;
        animation: pulse 1.5s infinite;
      }
      
      @keyframes pulse {
        0%, 100% { opacity: 1; transform: scale(1); }
        50% { opacity: 0.5; transform: scale(1.2); }
      }

      #start-screen {
        position: fixed;
        top: 0; left: 0; right: 0; bottom: 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        display: none;
        align-items: center;
        justify-content: center;
        z-index: 3000;
        color: white;
      }

      #start-screen.show { display: flex; }
      #start-screen.hidden { display: none; }

      .start-content {
        text-align: center;
        max-width: 600px;
        padding: 40px;
      }

      .start-content h1 {
        font-size: 48px;
        margin-bottom: 20px;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
      }

      .start-content p {
        font-size: 18px;
        margin-bottom: 30px;
        line-height: 1.6;
      }

      #enter-vr-btn {
        padding: 20px 50px;
        font-size: 24px;
        background: #4CAF50;
        border: none;
        color: white;
        border-radius: 50px;
        cursor: pointer;
        transition: all 0.3s;
        box-shadow: 0 4px 15px rgba(0,0,0,0.3);
      }

      #enter-vr-btn:hover {
        background: #45a049;
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.4);
      }
      
      #loading-overlay {
        position: fixed;
        top: 0; left: 0; right: 0; bottom: 0;
        background: rgba(0, 0, 0, 0.9);
        display: flex;
        align-items: center;
        justify-content: center;
        z-index: 4000;
        color: white;
        flex-direction: column;
      }
      
      #loading-overlay.hidden { display: none; }
      
      .loading-content {
        text-align: center;
        max-width: 500px;
      }
      
      .loading-content h2 {
        font-size: 32px;
        margin-bottom: 20px;
      }
      
      .progress-bar {
        width: 100%;
        height: 30px;
        background: #333;
        border-radius: 15px;
        overflow: hidden;
        margin: 20px 0;
      }
      
      .progress-fill {
        height: 100%;
        background: linear-gradient(90deg, #4CAF50, #81C784);
        width: 0%;
        transition: width 0.3s;
      }
      
      .loading-status {
        font-size: 16px;
        color: #81C784;
        margin-top: 10px;
      }
    </style>
  </head>
  <body>
    <!-- Loading Screen -->
    <div id="loading-overlay">
      <div class="loading-content">
        <h2>üé§ Loading Speech Models...</h2>
        <div class="progress-bar">
          <div id="progress-fill" class="progress-fill"></div>
        </div>
        <div id="loading-status" class="loading-status">Initializing...</div>
        <p style="font-size: 14px; color: #999; margin-top: 20px;">
          First load may take 1-2 minutes<br>
          Models are cached for future visits
        </p>
      </div>
    </div>

    <!-- Start Screen -->
    <div id="start-screen">
      <div class="start-content">
        <h1>üó£Ô∏è Language Practice VR</h1>
        <p>Quest-compatible offline speech recognition powered by Vosk</p>
        <button id="enter-vr-btn">Enter VR Experience</button>
        <div style="margin-top: 30px; font-size: 14px; opacity: 0.8;">
          <p>‚úì Works on Meta Quest<br>
          ‚úì Offline speech recognition<br>
          ‚úì Interactive scenarios</p>
        </div>
      </div>
    </div>

    <!-- Desktop UI -->
    <div id="ui">
      <h2>üéì Language VR (Vosk)</h2>
      
      <div class="status" id="status">Ready to start</div>
      <div class="status" id="speech-status">Speech: Initializing...</div>
      
      <h3>Choose Language:</h3>
      <div class="language-selector">
        <button class="lang-btn active" data-lang="es-ES" data-name="Spanish">üá™üá∏ Spanish</button>
        <button class="lang-btn" data-lang="fr-FR" data-name="French">üá´üá∑ French</button>
        <button class="lang-btn" data-lang="de-DE" data-name="German">üá©üá™ German</button>
        <button class="lang-btn" data-lang="nl-NL" data-name="Dutch">üá≥üá± Dutch</button>
      </div>
      
      <h3>Scenarios:</h3>
      <div class="scenario-list">
        <button class="scenario-btn active" data-scenario="greetings">
          üëã Greetings & Introductions
        </button>
        <button class="scenario-btn" data-scenario="restaurant">
          üçΩÔ∏è Restaurant Conversation
        </button>
        <button class="scenario-btn" data-scenario="shopping">
          üõçÔ∏è Shopping & Prices
        </button>
        <button class="scenario-btn" data-scenario="directions">
          üó∫Ô∏è Asking for Directions
        </button>
      </div>
      
      <div id="score">Score: 0 üåü</div>
      
      <div class="info">
        <strong>Recognition:</strong> <span id="recognition-type">Detecting...</span><br>
        <strong>How to use:</strong><br>
        1. Put on your VR headset<br>
        2. Listen to the NPC speak<br>
        3. Repeat the phrase clearly<br>
        4. Get instant feedback!<br><br>
        <strong>Controls:</strong> Right thumbstick = rotate NPC
      </div>
    </div>

    <!-- Current Phrase Display -->
    <div id="current-phrase">
      <div id="phrase-text">Hola, ¬øc√≥mo est√°s?</div>
      <div id="translation">Hello, how are you?</div>
    </div>

    <!-- Feedback Banner -->
    <div id="feedback-banner"></div>

    <!-- VR Scene -->
    <a-scene background="color: #87CEEB" renderer="antialias: true; colorManagement: true" ui-toggle-controller>
      <!-- Preload all 3D models using A-Frame's asset management system -->
      <!-- This shows a built-in loading screen and ensures all models are cached before scene starts -->
      <a-assets timeout="30000">
        <!-- Restaurant Environment -->
        <a-asset-item id="temple-model-asset" src="assets/bagan_-_khayiminga_temple_interior.glb"></a-asset-item>
        
        <!-- Shopping Environment -->
        <a-asset-item id="moosstock-model-asset" src="https://pub-65c21cd4f13345fcb1574dc28def6a19.r2.dev/moosstock_mountain_peak_3024_m.glb"></a-asset-item>
        
        <!-- Directions Environment -->
        <a-asset-item id="hintze-hall-model-asset" src="https://pub-65c21cd4f13345fcb1574dc28def6a19.r2.dev/hintze_hall.glb"></a-asset-item>
      </a-assets>
      
      <!-- Lighting -->
      <a-entity light="type: ambient; intensity: 0.6"></a-entity>
      <a-entity light="type: directional; intensity: 0.8" position="2 4 2"></a-entity>
      <a-entity light="type: point; intensity: 0.5; color: #FFA500" position="0 2 -2"></a-entity>

      <!-- VR Camera Rig -->
      <a-entity id="rig" position="0 1.6 0" vr-locomotion>
        <a-entity id="camera" camera look-controls wasd-controls="acceleration: 20">
          <a-entity cursor="fuse: false; rayOrigin: mouse"
                    raycaster="objects: .clickable; far: 10"></a-entity>
        </a-entity>
        <a-entity id="left-hand" 
                  hand-controls="hand: left; handModelStyle: lowPoly"
                  oculus-touch-controls="hand: left"
                  visible="false"
                  laser-controls="hand: left"
                  raycaster="objects: .clickable; far: 10; lineColor: red; lineOpacity: 0.75"
                  raycaster-debug></a-entity>
        <a-entity id="right-hand" 
                  hand-controls="hand: right; handModelStyle: lowPoly"
                  oculus-touch-controls="hand: right"
                  visible="false"
                  laser-controls="hand: right"
                  raycaster="objects: .clickable; far: 10; lineColor: red; lineOpacity: 0.75"
                  raycaster-debug></a-entity>
      </a-entity>

      <!-- Player Body -->
      <a-entity id="local-body" mixamo-body="isMirror: false; modelPath: ../BoltVR/assets/Y Bot.fbx"></a-entity>

      <!-- NPC Tutor Body -->
      <a-entity id="npc-tutor" 
                mixamo-body="isMirror: true; color: #FF6B6B; modelPath: ../BoltVR/assets/Y Bot.fbx" 
                position="0 0 -2.5"
                language-npc>
        <a-text value="Mar√≠a - Spanish Tutor" 
                position="0 2.2 0" 
                align="center" 
                color="#333" 
                width="4"
                shader="msdf"
                font="https://cdn.aframe.io/fonts/Roboto-msdf.json"
                id="npc-name">
          </a-text>
        
        <a-entity id="speech-bubble" position="0 2 0.3" visible="false">
          <a-plane width="1.5" height="0.5" color="#FFFFFF" opacity="0.95"></a-plane>
          <a-text value="¬°Hola!" 
                  position="0 0 0.01" 
                  align="center" 
                  color="#333" 
                  width="1.3"
                  shader="msdf"
                  font="assets/fonts/Roboto-Regular-msdf.json"
                  negate="false"
                  id="bubble-text"></a-text>
        </a-entity>
      </a-entity>

      <!-- LEFT: Language Selection Panel -->
      <a-entity id="vr-language-panel" position="-2.5 2 -2" rotation="0 30 0">
        <a-plane width="1.2" height="1.8" color="#1a1a1a" opacity="0.9"></a-plane>
        
        <a-text value="LANGUAGE" 
                position="0 0.8 0.01" 
                align="center" 
                color="#4CAF50" 
                width="1"></a-text>
        
        <a-box id="vr-lang-spanish" 
               width="1" height="0.2" depth="0.05" 
               color="#4CAF50"
               position="0 0.4 0"
               class="clickable lang-button"
               vr-button
               data-lang="es-ES"
               data-name="Spanish"></a-box>
        <a-text value="üá™üá∏ Spanish" 
                position="0 0.4 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-lang-french" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 0.1 0"
               class="clickable lang-button"
               vr-button
               data-lang="fr-FR"
               data-name="French"></a-box>
        <a-text value="üá´üá∑ French" 
                position="0 0.1 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-lang-german" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 -0.2 0"
               class="clickable lang-button"
               vr-button
               data-lang="de-DE"
               data-name="German"></a-box>
        <a-text value="üá©üá™ German" 
                position="0 -0.2 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-lang-dutch" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 -0.5 0"
               class="clickable lang-button"
               vr-button
               data-lang="nl-NL"
               data-name="Dutch"></a-box>
        <a-text value="üá≥üá± Dutch" 
                position="0 -0.5 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
      </a-entity>
      
      <!-- RIGHT: Scenario Selection Panel -->
      <a-entity id="vr-scenario-panel" position="2.5 2 -2" rotation="0 -30 0">
        <a-plane width="1.2" height="1.8" color="#1a1a1a" opacity="0.9"></a-plane>
        
        <a-text value="SCENARIOS" 
                position="0 0.8 0.01" 
                align="center" 
                color="#4CAF50" 
                width="1"></a-text>
        
        <a-box id="vr-scenario-greetings" 
               width="1" height="0.2" depth="0.05" 
               color="#4CAF50"
               position="0 0.4 0"
               class="clickable scenario-button"
               vr-button
               data-scenario="greetings"></a-box>
        <a-text value="üëã Greetings" 
                position="0 0.4 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-scenario-restaurant" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 0.1 0"
               class="clickable scenario-button"
               vr-button
               data-scenario="restaurant"></a-box>
        <a-text value="üçΩÔ∏è Restaurant" 
                position="0 0.1 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-scenario-shopping" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 -0.2 0"
               class="clickable scenario-button"
               vr-button
               data-scenario="shopping"></a-box>
        <a-text value="üõçÔ∏è Shopping" 
                position="0 -0.2 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
        
        <a-box id="vr-scenario-directions" 
               width="1" height="0.2" depth="0.05" 
               color="#2196F3"
               position="0 -0.5 0"
               class="clickable scenario-button"
               vr-button
               data-scenario="directions"></a-box>
        <a-text value="üó∫Ô∏è Directions" 
                position="0 -0.5 0.03" 
                align="center" 
                color="#FFFFFF" 
                width="0.9"
                scale="0.6 0.6 0.6"></a-text>
      </a-entity>

      <!-- CENTER: VR UI Panel -->
      <a-entity id="vr-ui-panel" position="0 2.5 -1.5">
        <a-plane width="2" height="1.2" color="#1a1a1a" opacity="0.9"></a-plane>
        
        <a-text id="vr-phrase-text" 
                value="¬°Hola!" 
                position="0 0.45 0.01" 
                align="center" 
                color="#4CAF50" 
                width="1.8"
                shader="msdf"
                font="assets/fonts/Roboto-Regular-msdf.json"
                negate="false"
                wrap-count="30"></a-text>
        
        <a-text id="vr-translation-text" 
                value="Hello!" 
                position="0 0.3 0.01" 
                align="center" 
                color="#81C784" 
                width="1.8"
                shader="msdf"
                font="assets/fonts/Roboto-Regular-msdf.json"
                negate="false"
                wrap-count="30"></a-text>
        
        <a-text id="vr-instruction-text" 
                value="üé§ Listening... Speak now!" 
                position="0 0.1 0.01" 
                align="center" 
                color="#FFD700" 
                width="1.8"
                shader="msdf"
                font="assets/fonts/Roboto-Regular-msdf.json"
                negate="false"
                wrap-count="40"></a-text>
        
        <a-text id="vr-heard-text" 
                value="" 
                position="0 -0.05 0.01" 
                align="center" 
                color="#FFFFFF" 
                width="1.8"
                shader="msdf"
                font="assets/fonts/Roboto-Regular-msdf.json"
                negate="false"
                wrap-count="40"></a-text>
        
        <a-text id="vr-score-text" 
                value="Score: 0" 
                position="0 -0.25 0.01" 
                align="center" 
                color="#FFD700" 
                width="1.8"></a-text>
        
        <a-entity id="mic-visualizer" position="0 -0.45 0.01">
          <a-plane width="1.5" height="0.08" color="#333333"></a-plane>
          <a-plane id="mic-level-bar" 
                   width="0" 
                   height="0.08" 
                   color="#4CAF50" 
                   position="-0.75 0 0.01"
                   mic-level-visualizer></a-plane>
          <a-text id="mic-level-label"
                  value="Mic Level" 
                  position="0 -0.08 0.01" 
                  align="center" 
                  color="#888888" 
                  width="1"
                  scale="0.5 0.5 0.5"></a-text>
        </a-entity>
        
        <a-entity id="vr-buttons" position="0 -0.7 0.01">
          <a-box id="repeat-btn" 
                 width="0.5" height="0.15" depth="0.05" 
                 color="#2196F3"
                 position="-0.6 0 0"
                 class="clickable"
                 vr-button="action: repeat"></a-box>
          <a-text value="üîä REPEAT" 
                  position="-0.6 0 0.03" 
                  align="center" 
                  color="#FFFFFF" 
                  width="1"
                  scale="0.5 0.5 0.5"></a-text>
          
          <a-box id="next-btn" 
                 width="0.5" height="0.15" depth="0.05" 
                 color="#4CAF50"
                 position="-0.1 0 0"
                 class="clickable"
                 vr-button="action: next"></a-box>
          <a-text value="‚û°Ô∏è NEXT" 
                  position="-0.1 0 0.03" 
                  align="center" 
                  color="#FFFFFF" 
                  width="1"
                  scale="0.5 0.5 0.5"></a-text>
          
          <a-box id="play-pause-btn" 
                 width="0.5" height="0.15" depth="0.05" 
                 color="#4CAF50"
                 position="0.4 0 0"
                 class="clickable"
                 vr-button="action: play-pause"></a-box>
          <a-text id="play-pause-text"
                  value="‚è∏Ô∏è PAUSE" 
                  position="0.4 0 0.03" 
                  align="center" 
                  color="#FFFFFF" 
                  width="1"
                  scale="0.5 0.5 0.5"></a-text>
        </a-entity>
      </a-entity>

      <!-- Environments (same as index.html) -->
      <a-entity id="env-classroom" visible="true">
        <a-plane position="0 0 0" 
                 rotation="-90 0 0" 
                 width="20" 
                 height="20" 
                 color="#7BC8A4"
                 shadow="receive: true"></a-plane>
        <a-box position="0 2 -8" width="20" height="4" depth="0.2" color="#F0E68C"></a-box>
        <a-box position="-10 2 0" width="0.2" height="4" depth="16" color="#F0E68C"></a-box>
        <a-box position="10 2 0" width="0.2" height="4" depth="16" color="#F0E68C"></a-box>
        <a-box position="0 2.5 -7.8" width="4" height="2" depth="0.1" color="#FFFFFF"></a-box>
        <a-text value="Language Practice" 
                position="0 3.3 -7.7" 
                align="center" 
                color="#2196F3" 
                width="3"></a-text>
        <a-box position="0 0.4 -2" width="1.5" height="0.8" depth="1" color="#8B4513"></a-box>
        <a-sphere position="-3 1.5 -5" radius="0.3" color="#FF6B6B"></a-sphere>
        <a-sphere position="3 1.5 -5" radius="0.3" color="#4ECDC4"></a-sphere>
        <a-cylinder position="-4 0.5 -6" radius="0.2" height="1" color="#2ECC71"></a-cylinder>
        <a-cylinder position="4 0.5 -6" radius="0.2" height="1" color="#E74C3C"></a-cylinder>
        <a-text value="Stand here and speak clearly!" 
                position="0 0.01 0.5" 
                rotation="-90 0 0" 
                align="center" 
                color="#333" 
                width="6"></a-text>
      </a-entity>
      
      <a-entity id="env-restaurant" visible="false">
        <a-entity id="temple-model" 
                  gltf-model="#temple-model-asset" 
                  position="0 1 -4" 
                  rotation="0 180 0"
                  scale="2 2 2"
                  shadow="cast: true; receive: true"></a-entity>
        <a-plane position="0 0 0" 
                 rotation="-90 0 0" 
                 width="50" 
                 height="50" 
                 color="#8B7355"
                 opacity="0.8"
                 shadow="receive: true"></a-plane>
      </a-entity>
      
      <a-entity id="env-shopping" visible="false">
        <a-entity id="moosstock-mountain-model" 
                  gltf-model="#moosstock-model-asset" 
                  position="0 -67 10" 
                  rotation="0 90 0"
                  scale="80 80 80"
                  shadow="cast: true; receive: true"></a-entity>
        <a-plane position="0 0 0" 
                 rotation="-90 0 0" 
                 width="50" 
                 height="50" 
                 color="#D2B48C"
                 opacity="0"
                 shadow="receive: true"></a-plane>
      </a-entity>
      
      <a-entity id="env-directions" visible="false">
        <a-entity id="hintze-hall-model" 
                  gltf-model="#hintze-hall-model-asset" 
                  position="2.5 -0.5 -12.5" 
                  rotation="0 180 0"
                  scale="1 1 1"
                  shadow="cast: true; receive: true"></a-entity>
        <a-plane position="0 0 0" 
                 rotation="-90 0 0" 
                 width="50" 
                 height="50" 
                 color="#6B8E23"
                 opacity="0.8"
                 shadow="receive: true"></a-plane>
      </a-entity>
    </a-scene>

    <script>
      // ========================================
      // VOSK SPEECH RECOGNITION
      // ========================================
      
      const VoskRecognizer = {
        model: null,
        recognizer: null,
        audioContext: null,
        processor: null,
        analyser: null,
        microphoneStream: null,
        sourceNode: null,
        isInitialized: false,
        isListening: false,
        currentLanguage: 'es',
        onResult: null,
        onPartialResult: null,
        
        languageMap: {
          'es-ES': 'es',
          'fr-FR': 'fr',
          'de-DE': 'de',
          'nl-NL': 'nl'
        },
        
        async init(language, onProgress, onResult, onPartialResult) {
          console.log('[Vosk] Initializing for language:', language);
          this.currentLanguage = this.languageMap[language] || 'es';
          this.onResult = onResult;
          this.onPartialResult = onPartialResult;
          this.isListening = false;
          this.shouldProcessResults = false; // Initialize the flag
          
          try {
            // Show progress
            if (onProgress) onProgress(10, 'Loading Vosk library...');
            
            // Load model from local assets - Vosk expects tar.gz archives
            const modelPath = `assets/vosk-models/${this.currentLanguage}.tar.gz`;
            console.log('[Vosk] Loading model from:', modelPath);
            
            if (onProgress) onProgress(30, `Loading ${this.currentLanguage} model...`);
            
            // Create model - use relative path from current page location
            const baseUrl = window.location.href.substring(0, window.location.href.lastIndexOf('/'));
            const fullModelPath = `${baseUrl}/${modelPath}`;
            console.log('[Vosk] Full model URL:', fullModelPath);
            
            this.model = await Vosk.createModel(fullModelPath);
            console.log('[Vosk] ‚úì Model loaded');
            
            if (onProgress) onProgress(60, 'Creating recognizer...');
            
            // Create recognizer with 16kHz sample rate
            this.recognizer = new this.model.KaldiRecognizer(16000);
            this.recognizer.setWords(true);
            
            // Note: Grammar will be set later after LanguageApp initializes
            
            console.log('[Vosk] ‚úì Recognizer created');
            console.log('[Vosk] Recognizer methods:', Object.getOwnPropertyNames(Object.getPrototypeOf(this.recognizer)));
            console.log('[Vosk] Recognizer object:', this.recognizer);
            
            if (onProgress) onProgress(80, 'Setting up microphone...');
            
            // Setup audio processing
            await this.setupAudio();
            
            if (onProgress) onProgress(100, 'Ready!');
            
            this.isInitialized = true;
            console.log('[Vosk] ‚úì Fully initialized');
            
            return true;
          } catch (error) {
            console.error('[Vosk] Initialization error:', error);
            throw error;
          }
        },
        
        async setupAudio() {
          try {
            // Get microphone stream
            this.microphoneStream = await navigator.mediaDevices.getUserMedia({ 
              audio: {
                echoCancellation: true,
                noiseSuppression: true,
                sampleRate: 16000
              } 
            });
            
            console.log('[Vosk] Microphone access granted');
            
            // Create audio context with 16kHz sample rate (Vosk requirement)
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 16000
            });
            
            this.sourceNode = this.audioContext.createMediaStreamSource(this.microphoneStream);
            
            // Create analyser for mic level visualization
            this.analyser = this.audioContext.createAnalyser();
            this.analyser.fftSize = 256;
            this.analyser.smoothingTimeConstant = 0.8;
            
            // Create script processor for audio processing
            const bufferSize = 4096;
            this.processor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);
            
            let audioChunkCount = 0;
            
            // Listen for results from Vosk recognizer
            this.recognizer.on('result', (message) => {
              // Only process if we should be listening AND this is the current recognizer
              if (!this.shouldProcessResults || !this.recognizer || message.recognizerId !== this.recognizer.id) {
                console.log('[Vosk] Ignoring result - not listening or old recognizer');
                return;
              }
              
              console.log('[Vosk] Result event:', message, 'Recognizer ID:', message.recognizerId);
              // Access the nested result.text property (Quest-compatible syntax)
              const text = (message.result && message.result.text) || message.text;
              if (text && text.trim()) {
                console.log('[Vosk] ‚úì Recognized:', text);
                if (this.onResult) {
                  this.onResult(text, 1.0);
                }
              }
            });
            
            this.recognizer.on('partialresult', (message) => {
              // Only process if we should be listening AND this is the current recognizer
              if (!this.shouldProcessResults || !this.recognizer || message.recognizerId !== this.recognizer.id) {
                return; // Silent ignore for partials
              }
              
              // Access the nested result.partial property (Quest-compatible syntax)
              const partial = (message.result && message.result.partial) || message.partial;
              if (partial && partial.trim()) {
                console.log('[Vosk] Partial:', partial);
                // Call onPartialResult callback if provided
                if (this.onPartialResult) {
                  this.onPartialResult(partial);
                }
              }
            });
            
            this.processor.onaudioprocess = (e) => {
              if (!this.isListening || !this.recognizer) return;
              
              audioChunkCount++;
              // Reduced logging frequency: log every 200 chunks (~13 seconds) instead of every 50 (~3 seconds)
              if (audioChunkCount % 200 === 0) {
                console.log('[Vosk] Processing audio chunks...', audioChunkCount);
              }
              
              // Vosk expects the AudioBuffer directly
              try {
                this.recognizer.acceptWaveform(e.inputBuffer);
              } catch (err) {
                console.error('[Vosk] Processing error:', err);
              }
            };
            
            // Connect audio pipeline: source -> analyser -> processor -> destination
            this.sourceNode.connect(this.analyser);
            this.analyser.connect(this.processor);
            this.processor.connect(this.audioContext.destination);
            
            console.log('[Vosk] ‚úì Audio pipeline ready with analyser');
            
            // Directly set analyser on mic-level-bar entity
            const micLevelBar = document.querySelector('#mic-level-bar');
            if (micLevelBar && micLevelBar.components && micLevelBar.components['mic-level-visualizer']) {
              micLevelBar.components['mic-level-visualizer'].analyser = this.analyser;
              console.log('[Vosk] ‚úì Analyser set on mic-level-bar entity');
            } else {
              console.warn('[Vosk] Could not find mic-level-bar entity or component');
            }
          } catch (error) {
            console.error('[Vosk] Audio setup error:', error);
            throw error;
          }
        },
        
        start() {
          if (!this.isInitialized) {
            console.error('[Vosk] Not initialized');
            return;
          }
          
          // Check if already listening before starting
          if (this.isListening) {
            console.warn('[Vosk] Already listening, ensuring flags are synchronized');
            this.shouldProcessResults = true; // Re-enable processing just in case
            return;
          }
          
          this.isListening = true;
          this.shouldProcessResults = true; // Enable result processing
          console.log('[Vosk] Started listening');
        },
        
        stop() {
          this.isListening = false;
          this.shouldProcessResults = false; // Disable result processing
          
          // Get final result before stopping
          if (this.recognizer) {
            try {
              console.log('[Vosk] Stopping - getting final result...');
              // Use retrieveFinalResult() method
              this.recognizer.retrieveFinalResult();
              // The result will come via the 'result' event listener
            } catch (err) {
              console.error('[Vosk] Final result error:', err);
            }
          }
          
          console.log('[Vosk] Stopped listening');
        },
        
        cleanup() {
          console.log('[Vosk] Cleaning up audio pipeline...');
          
          // Stop listening
          this.isListening = false;
          
          // Disconnect audio nodes
          if (this.sourceNode) {
            try {
              this.sourceNode.disconnect();
            } catch (e) {
              console.log('[Vosk] Source already disconnected');
            }
            this.sourceNode = null;
          }
          
          if (this.analyser) {
            try {
              this.analyser.disconnect();
            } catch (e) {
              console.log('[Vosk] Analyser already disconnected');
            }
            this.analyser = null;
          }
          
          if (this.processor) {
            try {
              this.processor.disconnect();
              this.processor.onaudioprocess = null;
            } catch (e) {
              console.log('[Vosk] Processor already disconnected');
            }
            this.processor = null;
          }
          
          // Stop microphone stream
          if (this.microphoneStream) {
            this.microphoneStream.getTracks().forEach(track => {
              track.stop();
              console.log('[Vosk] Stopped microphone track');
            });
            this.microphoneStream = null;
          }
          
          // Close audio context
          if (this.audioContext) {
            try {
              this.audioContext.close();
              console.log('[Vosk] Audio context closed');
            } catch (e) {
              console.log('[Vosk] Audio context already closed');
            }
            this.audioContext = null;
          }
          
          // Remove recognizer (this will stop it from receiving events)
          if (this.recognizer) {
            try {
              this.recognizer.remove();
              console.log('[Vosk] Recognizer removed');
            } catch (e) {
              console.log('[Vosk] Recognizer already removed');
            }
            this.recognizer = null;
          }
          
          // Clean up model
          if (this.model) {
            this.model = null;
          }
          
          console.log('[Vosk] ‚úì Cleanup complete');
        },
        
        updateVoskGrammar() {
          if (!this.recognizer) {
            console.log('[Vosk] Recognizer not initialized, skipping grammar update');
            return;
          }
          
          // Check if LanguageApp is available
          if (!window.LanguageApp || !window.LanguageApp.phrases || !window.LanguageApp.currentLanguage) {
            console.log('[Vosk] LanguageApp not yet initialized, skipping grammar update');
            return;
          }
          
          // Get all phrases for current language across all scenarios
          const allPhrases = [];
          const scenarios = ['restaurant', 'shopping', 'directions', 'greetings'];
          
          scenarios.forEach(scenario => {
            const scenarioPhrases = window.LanguageApp.phrases[scenario][window.LanguageApp.currentLanguage];
            if (scenarioPhrases) {
              scenarioPhrases.forEach(p => {
                // Add the main phrase
                allPhrases.push(p.text);
                
                // Add variations without punctuation
                const noPunct = p.text.replace(/[¬ø¬°?!.,]/g, '').trim();
                if (noPunct !== p.text) {
                  allPhrases.push(noPunct);
                }
                
                // Add lowercase version
                allPhrases.push(p.text.toLowerCase());
                allPhrases.push(noPunct.toLowerCase());
                
                // Add individual words for better word-level recognition
                const words = noPunct.toLowerCase().split(/\s+/);
                words.forEach(word => {
                  if (word.length > 2) { // Skip very short words
                    allPhrases.push(word);
                  }
                });
              });
            }
          });
          
          if (allPhrases.length === 0) {
            console.log('[Vosk] No phrases found for grammar');
            return;
          }
          
          // Remove duplicates
          const uniquePhrases = [...new Set(allPhrases)];
          
          // Vosk expects a JSON array of phrases
          const grammar = JSON.stringify(uniquePhrases);
          
          try {
            // Set grammar if the method exists
            if (typeof this.recognizer.setGrammar === 'function') {
              this.recognizer.setGrammar(grammar);
              console.log('[Vosk] Grammar updated with', uniquePhrases.length, 'phrases/words (from', allPhrases.length, 'total including variations)');
            } else {
              console.log('[Vosk] setGrammar not available, using default model vocabulary');
            }
          } catch (error) {
            console.warn('[Vosk] Could not set grammar:', error);
          }
        },
        
        async switchLanguage(language, onProgress) {
          console.log('[Vosk] Switching to language:', language);
          
          // Clean up everything from the old language
          this.cleanup();
          
          // Reinitialize with new language
          this.isInitialized = false;
          await this.init(language, onProgress, this.onResult, this.onPartialResult);
        }
      };
      
      // ========================================
      // LANGUAGE APP CORE (Modified for Vosk)
      // ========================================
      
      const LanguageApp = {
        currentLanguage: 'es-ES',
        currentLanguageName: 'Spanish',
        currentScenario: 'greetings',
        currentPhrase: null,
        currentPhraseIndex: 0,
        score: 0,
        recognition: null,
        synthesis: window.speechSynthesis,
        isListening: false,
        isPaused: false,
        audioContext: null,
        microphone: null,
        analyser: null,
        micLevelBar: null,
        voices: [],
        selectedVoice: null,
        useVosk: false,
        
        // Phrase database (same as index.html)
        phrases: {
          'greetings': {
            'es-ES': [
              { text: '¬°Hola!', translation: 'Hello!', difficulty: 1, audio: 'hola.mp3' },
              { text: '¬øC√≥mo est√°s?', translation: 'How are you?', difficulty: 1, audio: 'como_estas.mp3' },
              { text: 'Me llamo Mar√≠a', translation: 'My name is Mar√≠a', difficulty: 1, audio: 'me_llamo_maria.mp3' },
              { text: 'Mucho gusto', translation: 'Nice to meet you', difficulty: 1, audio: 'mucho_gusto.mp3' },
              { text: 'Buenos d√≠as', translation: 'Good morning', difficulty: 1, audio: 'buenos_dias.mp3' },
              { text: '¬øC√≥mo te llamas?', translation: 'What is your name?', difficulty: 2, audio: 'como_te_llamas.mp3' }
            ],
            'fr-FR': [
              { text: 'Bonjour!', translation: 'Hello!', difficulty: 1, audio: 'bonjour.mp3' },
              { text: 'Comment allez-vous?', translation: 'How are you?', difficulty: 1, audio: 'comment_allez_vous.mp3' },
              { text: 'Je m\'appelle Marie', translation: 'My name is Marie', difficulty: 1, audio: 'je_mappelle_marie.mp3' },
              { text: 'Enchant√©', translation: 'Nice to meet you', difficulty: 1, audio: 'enchante.mp3' }
            ],
            'de-DE': [
              { text: 'Hallo!', translation: 'Hello!', difficulty: 1, audio: 'hallo.mp3' },
              { text: 'Wie geht es dir?', translation: 'How are you?', difficulty: 1, audio: 'wie_geht_es_dir.mp3' },
              { text: 'Ich hei√üe Maria', translation: 'My name is Maria', difficulty: 1, audio: 'ich_heisse_maria.mp3' },
              { text: 'Freut mich', translation: 'Nice to meet you', difficulty: 1, audio: 'freut_mich.mp3' }
            ],
            'nl-NL': [
              { text: 'Hallo!', translation: 'Hello!', difficulty: 1, audio: 'hallo.mp3' },
              { text: 'Hoe gaat het?', translation: 'How are you?', difficulty: 1, audio: 'hoe_gaat_het.mp3' },
              { text: 'Ik heet Maria', translation: 'My name is Maria', difficulty: 1, audio: 'ik_heet_maria.mp3' },
              { text: 'Aangenaam', translation: 'Nice to meet you', difficulty: 1, audio: 'aangenaam.mp3' },
              { text: 'Goedemorgen', translation: 'Good morning', difficulty: 1, audio: 'goedemorgen.mp3' },
              { text: 'Hoe heet je?', translation: 'What is your name?', difficulty: 2, audio: 'hoe_heet_je.mp3' }
            ]
          },
          'restaurant': {
            'es-ES': [
              { text: '¬øQu√© desea ordenar?', translation: 'What would you like to order?', difficulty: 2, audio: 'que_desea_ordenar.mp3' },
              { text: 'La cuenta, por favor', translation: 'The bill, please', difficulty: 2, audio: 'la_cuenta_por_favor.mp3' },
              { text: 'Una mesa para dos', translation: 'A table for two', difficulty: 2, audio: 'una_mesa_para_dos.mp3' },
              { text: '¬øTiene men√∫ del d√≠a?', translation: 'Do you have a daily menu?', difficulty: 3, audio: 'tiene_menu_del_dia.mp3' }
            ],
            'fr-FR': [
              { text: 'Qu\'est-ce que vous d√©sirez?', translation: 'What would you like?', difficulty: 2, audio: 'quest_ce_que_vous_desirez.mp3' },
              { text: 'L\'addition, s\'il vous pla√Æt', translation: 'The bill, please', difficulty: 2, audio: 'laddition_sil_vous_plait.mp3' },
              { text: 'Une table pour deux', translation: 'A table for two', difficulty: 2, audio: 'une_table_pour_deux.mp3' }
            ],
            'de-DE': [
              { text: 'Was m√∂chten Sie bestellen?', translation: 'What would you like to order?', difficulty: 2, audio: 'was_mochten_sie_bestellen.mp3' },
              { text: 'Die Rechnung, bitte', translation: 'The bill, please', difficulty: 2, audio: 'die_rechnung_bitte.mp3' },
              { text: 'Ein Tisch f√ºr zwei', translation: 'A table for two', difficulty: 2, audio: 'ein_tisch_fur_zwei.mp3' }
            ],
            'nl-NL': [
              { text: 'Wat wilt u bestellen?', translation: 'What would you like to order?', difficulty: 2, audio: 'wat_wilt_u_bestellen.mp3' },
              { text: 'De rekening, alstublieft', translation: 'The bill, please', difficulty: 2, audio: 'de_rekening_alstublieft.mp3' },
              { text: 'Een tafel voor twee', translation: 'A table for two', difficulty: 2, audio: 'een_tafel_voor_twee.mp3' },
              { text: 'Heeft u een dagmenu?', translation: 'Do you have a daily menu?', difficulty: 3, audio: 'heeft_u_een_dagmenu.mp3' }
            ]
          },
          'shopping': {
            'es-ES': [
              { text: '¬øCu√°nto cuesta?', translation: 'How much does it cost?', difficulty: 2, audio: 'cuanto_cuesta.mp3' },
              { text: '¬øTiene esto en otro color?', translation: 'Do you have this in another color?', difficulty: 3, audio: 'tiene_esto_en_otro_color.mp3' },
              { text: 'Me gustar√≠a comprar esto', translation: 'I would like to buy this', difficulty: 2, audio: 'me_gustaria_comprar_esto.mp3' }
            ],
            'fr-FR': [
              { text: 'Combien √ßa co√ªte?', translation: 'How much does it cost?', difficulty: 2, audio: 'combien_ca_coute.mp3' },
              { text: 'Je voudrais acheter ceci', translation: 'I would like to buy this', difficulty: 2, audio: 'je_voudrais_acheter_ceci.mp3' }
            ],
            'de-DE': [
              { text: 'Was kostet das?', translation: 'How much does it cost?', difficulty: 2, audio: 'was_kostet_das.mp3' },
              { text: 'Ich m√∂chte das kaufen', translation: 'I would like to buy this', difficulty: 2, audio: 'ich_mochte_das_kaufen.mp3' }
            ],
            'nl-NL': [
              { text: 'Hoeveel kost dit?', translation: 'How much does this cost?', difficulty: 2, audio: 'hoeveel_kost_dit.mp3' },
              { text: 'Heeft u dit in een andere kleur?', translation: 'Do you have this in another color?', difficulty: 3, audio: 'heeft_u_dit_in_een_andere_kleur.mp3' },
              { text: 'Ik wil dit graag kopen', translation: 'I would like to buy this', difficulty: 2, audio: 'ik_wil_dit_graag_kopen.mp3' }
            ]
          },
          'directions': {
            'es-ES': [
              { text: '¬øD√≥nde est√° la estaci√≥n?', translation: 'Where is the station?', difficulty: 2, audio: 'donde_esta_la_estacion.mp3' },
              { text: 'Gire a la derecha', translation: 'Turn right', difficulty: 2, audio: 'gire_a_la_derecha.mp3' },
              { text: 'Siga recto', translation: 'Go straight', difficulty: 2, audio: 'siga_recto.mp3' }
            ],
            'fr-FR': [
              { text: 'O√π est la gare?', translation: 'Where is the station?', difficulty: 2, audio: 'ou_est_la_gare.mp3' },
              { text: 'Tournez √† droite', translation: 'Turn right', difficulty: 2, audio: 'tournez_a_droite.mp3' }
            ],
            'de-DE': [
              { text: 'Wo ist der Bahnhof?', translation: 'Where is the station?', difficulty: 2, audio: 'wo_ist_der_bahnhof.mp3' },
              { text: 'Biegen Sie rechts ab', translation: 'Turn right', difficulty: 2, audio: 'biegen_sie_rechts_ab.mp3' }
            ],
            'nl-NL': [
              { text: 'Waar is het station?', translation: 'Where is the station?', difficulty: 2, audio: 'waar_is_het_station.mp3' },
              { text: 'Ga naar rechts', translation: 'Turn right', difficulty: 2, audio: 'ga_naar_rechts.mp3' },
              { text: 'Ga rechtdoor', translation: 'Go straight', difficulty: 2, audio: 'ga_rechtdoor.mp3' }
            ]
          }
        },

        async init() {
          console.log('[Language App] Initializing with Vosk support...');
          
          // Initialize flags
          this.audioUnlocked = false;
          this.waitingForInteraction = false;
          
          // Store timeout IDs for cancellation
          this.pendingTimeouts = [];
          
          // Add speaking flag to prevent overlapping audio
          this.isSpeaking = false;
          
          // Store reference to current audio playback for cancellation
          this.currentAudio = null;
          
          // Initialize Speech Synthesis (CRITICAL - was missing!)
          this.synthesis = window.speechSynthesis;
          console.log('[Language App] Speech Synthesis initialized:', this.synthesis);
          
          // Detect which recognition system to use
          await this.detectRecognitionSystem();
          
          // Load voices for TTS
          this.loadVoices();
          
          // Initialize microphone visualizer
          this.initMicrophoneVisualizer();
          
          // Setup UI
          this.setupUIListeners();
          this.setupVRButtons();
          
          // Wait for scene
          const scene = document.querySelector('a-scene');
          if (scene.hasLoaded) {
            this.onSceneLoaded();
          } else {
            scene.addEventListener('loaded', () => this.onSceneLoaded());
          }
          
          console.log('[Language App] Initialization complete');
        },

        async detectRecognitionSystem() {
          console.log('[Detection] Checking recognition system...');
          console.log('[Detection] User Agent:', navigator.userAgent);
          
          const loadingOverlay = document.getElementById('loading-overlay');
          const progressFill = document.getElementById('progress-fill');
          const loadingStatus = document.getElementById('loading-status');
          
          // Check for URL parameter to force Vosk mode
          const urlParams = new URLSearchParams(window.location.search);
          const forceVosk = urlParams.get('vosk') === 'true';
          
          // Detect Quest browser - Meta Quest browsers identify themselves
          const isQuestBrowser = /OculusBrowser|Quest/i.test(navigator.userAgent);
          
          // Check for Web Speech API
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          
          // Force Vosk on Quest browsers since Web Speech API doesn't work reliably there
          if (SpeechRecognition && !forceVosk && !isQuestBrowser) {
            console.log('[Detection] Web Speech API available');
            document.getElementById('recognition-type').textContent = 'Web Speech API (Online)';
            this.useVosk = false;
            
            // Update VR mic level label
            const micLevelLabel = document.getElementById('mic-level-label');
            if (micLevelLabel) {
              micLevelLabel.setAttribute('value', 'Mic Level (Web Speech API)');
            }
            
            // Initialize Web Speech API
            this.initWebSpeechAPI();
            
            // Hide loading
            loadingOverlay.classList.add('hidden');
          } else {
            if (forceVosk) {
              console.log('[Detection] Vosk mode forced via URL parameter');
            } else if (isQuestBrowser) {
              console.log('[Detection] Quest browser detected, using Vosk');
            } else {
              console.log('[Detection] Web Speech API not available, using Vosk');
            }
            document.getElementById('recognition-type').textContent = 'Vosk (Offline)';
            this.useVosk = true;
            
            // Update VR mic level label
            const micLevelLabel = document.getElementById('mic-level-label');
            if (micLevelLabel) {
              micLevelLabel.setAttribute('value', 'Mic Level (Vosk)');
            }
            
            // Show loading and initialize Vosk
            loadingOverlay.classList.remove('hidden');
            
            try {
              await VoskRecognizer.init(
                this.currentLanguage,
                (progress, status) => {
                  progressFill.style.width = progress + '%';
                  loadingStatus.textContent = status;
                },
                (text, confidence) => {
                  this.onVoskResult(text, confidence);
                },
                (partial) => {
                  // Callback for partial results
                  this.onVoskPartialResult(partial);
                }
              );
              
              // Share VoskRecognizer's analyser with LanguageApp for mic level bar
              if (VoskRecognizer.analyser) {
                console.log('[Detection] Using Vosk analyser for mic level visualization');
                this.analyser = VoskRecognizer.analyser;
                this.audioContext = VoskRecognizer.audioContext;
              }
              
              // Hide loading after success
              setTimeout(() => {
                loadingOverlay.classList.add('hidden');
              }, 500);
            } catch (error) {
              console.error('[Detection] Vosk initialization failed:', error);
              loadingStatus.innerHTML = `
                <div style="color: #f44336; max-width: 700px; text-align: left; padding: 20px; background: rgba(0,0,0,0.8); border-radius: 10px;">
                  <h3 style="color: #f44336; margin-top: 0;">‚ùå Vosk Model Not Found</h3>
                  <p style="color: white;"><strong>Error:</strong> ${error.message || 'Model files missing'}</p>
                  <p style="color: white;"><strong>Expected:</strong> <code style="color: #4CAF50;">languageVR/assets/vosk-models/es.tar.gz</code></p>
                  <br>
                  <h4 style="color: white;">üì¶ Package Models:</h4>
                  <p style="color: white;">The Vosk models need to be packaged as tar.gz files.</p>
                  <ol style="color: white; line-height: 1.8;">
                    <li>Open PowerShell or Command Prompt in the <code>languageVR</code> folder</li>
                    <li>Run: <code style="color: #4CAF50;">package-vosk-models.bat</code></li>
                    <li>This will create:
                      <pre style="color: #4CAF50; background: black; padding: 10px; margin: 10px 0;">
assets/vosk-models/es.tar.gz
assets/vosk-models/fr.tar.gz
assets/vosk-models/de.tar.gz
assets/vosk-models/nl.tar.gz</pre>
                    </li>
                    <li>Reload this page</li>
                  </ol>
                  <br>
                  <p style="color: #FFD700;"><strong>üí° Quick Test:</strong> Remove <code>?vosk=true</code> from URL to use Web Speech API (no packaging needed)</p>
                  <br>
                  <button onclick="window.location.href = window.location.pathname" style="padding: 10px 20px; background: #4CAF50; color: white; border: none; border-radius: 5px; cursor: pointer; font-size: 16px;">
                    ‚Üê Back to Web Speech API
                  </button>
                </div>
              `;
            }
          }
        },

        initWebSpeechAPI() {
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          const SpeechGrammarList = window.SpeechGrammarList || window.webkitSpeechGrammarList;
          
          this.recognition = new SpeechRecognition();
          this.recognition.continuous = false;
          this.recognition.interimResults = false;
          this.recognition.maxAlternatives = 3;
          this.recognition.lang = this.currentLanguage;
          
          // Add grammar hints for better accuracy
          if (SpeechGrammarList) {
            this.updateSpeechGrammar();
          } else {
            console.log('[Web Speech] Grammar hints not supported by this browser');
          }

          console.log('[Web Speech] Initialized for:', this.currentLanguage);

          this.recognition.onstart = () => {
            this.isListening = true;
            this.updateSpeechStatus('üé§ Listening...', 'active');
            this.updateVRText('vr-instruction-text', 'üé§ SPEAK NOW!');
          };

          this.recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            const confidence = event.results[0][0].confidence;
            console.log('[Web Speech] Heard:', transcript, 'Confidence:', confidence);
            
            this.updateVRText('vr-heard-text', 'You said: "' + transcript + '"');
            this.checkAnswer(transcript, confidence);
          };

          this.recognition.onerror = (event) => {
            console.error('[Web Speech] Error:', event.error);
            
            if (!this.isListening) return;
            
            if (event.error === 'no-speech') {
              this.updateVRText('vr-instruction-text', 'üé§ NO SPEECH HEARD! Speak LOUDER');
            } else if (event.error === 'not-allowed') {
              this.updateVRText('vr-instruction-text', '‚ö†Ô∏è Microphone blocked!');
            }
            
            this.isListening = false;
            
            // Retry
            if (event.error !== 'not-allowed' && event.error !== 'aborted') {
              setTimeout(() => {
                if (this.currentPhrase) this.startListening();
              }, 2000);
            }
          };

          this.recognition.onend = () => {
            this.isListening = false;
            setTimeout(() => {
              if (this.currentPhrase && !this.isListening) {
                this.startListening();
              }
            }, 1000);
          };

          this.updateSpeechStatus('Web Speech API ready', 'active');
        },
        
        updateSpeechGrammar() {
          // Build grammar from all phrases in current language
          const SpeechGrammarList = window.SpeechGrammarList || window.webkitSpeechGrammarList;
          if (!SpeechGrammarList || !this.recognition) return;
          
          const scenarioPhrases = this.phrases[this.currentScenario][this.currentLanguage];
          if (!scenarioPhrases || scenarioPhrases.length === 0) return;
          
          // Create JSGF grammar (Java Speech Grammar Format)
          // Remove punctuation from phrases for grammar
          const cleanPhrases = scenarioPhrases.map(p => p.text.replace(/[¬ø¬°?!.,]/g, '').trim());
          const phraseList = cleanPhrases.join(' | ');
          const grammar = `#JSGF V1.0; grammar phrases; public <phrase> = ${phraseList} ;`;
          
          try {
            const grammarList = new SpeechGrammarList();
            grammarList.addFromString(grammar, 1); // Weight: 1 = highest priority
            this.recognition.grammars = grammarList;
            
            console.log('[Web Speech] ‚úì Grammar updated with', scenarioPhrases.length, 'phrases:', cleanPhrases.join(', '));
          } catch (error) {
            console.warn('[Web Speech] Grammar hint error (not critical):', error);
          }
        },

        onVoskResult(text, confidence) {
          console.log('[Vosk Result]:', text);
          this.updateVRText('vr-heard-text', 'You said: "' + text + '"');
          this.checkAnswer(text, confidence);
        },
        
        onVoskPartialResult(partial) {
          console.log('[Vosk Partial]:', partial);
          // Display partial result in light gray to show recognition is happening
          this.updateVRText('vr-heard-text', 'Hearing: "' + partial + '"...');
          const heardEl = document.getElementById('vr-heard-text');
          if (heardEl) {
            heardEl.setAttribute('color', '#CCCCCC');
          }
        },

        onSceneLoaded() {
          console.log('[Language App] Scene loaded');
          this.updateStatus('VR Scene loaded');
          
          // Check if we're in VR mode or Quest browser
          const scene = document.querySelector('a-scene');
          const isQuestBrowser = /OculusBrowser|Quest/i.test(navigator.userAgent);
          
          // Listen for VR mode changes
          scene.addEventListener('enter-vr', () => {
            console.log('[Language App] ‚úì Entered VR mode');
          });
          
          scene.addEventListener('exit-vr', () => {
            console.log('[Language App] ‚úó Exited VR mode');
          });
          
          if (scene.is('vr-mode')) {
            console.log('[Language App] Starting in VR mode');
          } else {
            console.log('[Language App] Starting in desktop mode');
          }
          
          // Start experience with a delay to allow everything to initialize
          setTimeout(() => {
            console.log('[Language App] Starting first phrase...');
            
            // Initialize grammar hints before starting
            if (!this.useVosk && this.recognition) {
              this.updateSpeechGrammar();
            } else if (this.useVosk && VoskRecognizer.recognizer) {
              // Now that LanguageApp is initialized, we can set Vosk grammar
              VoskRecognizer.updateVoskGrammar();
            }
            
            this.nextPhrase();
          }, 2000);
        },

        loadVoices() {
          // Check if synthesis is available
          if (!this.synthesis) {
            console.warn('[Voices] Speech Synthesis not available on this browser');
            return;
          }
          
          const loadVoicesImpl = () => {
            if (!this.synthesis) return;
            
            this.voices = this.synthesis.getVoices();
            if (this.voices.length > 0) {
              // Use the first 2 characters of currentLanguage to match voice (e.g., 'es-ES' -> 'es', 'fr-FR' -> 'fr')
              const langCode = this.currentLanguage.substring(0, 2);
              this.selectedVoice = this.voices.find(v => v.lang.startsWith(langCode)) || this.voices[0];
              console.log('[Voices] Selected:', this.selectedVoice.name);
            }
          };
          
          loadVoicesImpl();
          if (this.synthesis && this.synthesis.onvoiceschanged !== undefined) {
            this.synthesis.onvoiceschanged = loadVoicesImpl;
          }
          setTimeout(loadVoicesImpl, 500);
        },

        async initMicrophoneVisualizer() {
          try {
            // If using Vosk, the analyser will be shared from VoskRecognizer after init
            // So we just start the visualization loop and wait for the analyser
            if (this.useVosk === undefined) {
              // Not yet determined, create temporary analyser (will be replaced if Vosk is used)
              const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
              this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
              this.microphone = this.audioContext.createMediaStreamSource(stream);
              this.analyser = this.audioContext.createAnalyser();
              this.analyser.fftSize = 256;
              this.analyser.smoothingTimeConstant = 0.8;
              
              this.microphone.connect(this.analyser);
              console.log('[Mic Visualizer] ‚úì Temporary analyser created');
            } else if (!this.useVosk) {
              // Using Web Speech API, create our own analyser
              const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
              this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
              this.microphone = this.audioContext.createMediaStreamSource(stream);
              this.analyser = this.audioContext.createAnalyser();
              this.analyser.fftSize = 256;
              this.analyser.smoothingTimeConstant = 0.8;
              
              this.microphone.connect(this.analyser);
              console.log('[Mic Visualizer] ‚úì Web Speech API analyser created');
            }
            // If using Vosk, analyser will be shared after VoskRecognizer.init()
            // Mic level visualization is now handled by the 'mic-level-visualizer' A-Frame component
            
            console.log('[Mic Visualizer] ‚úì Initialized');
          } catch (error) {
            console.error('[Mic Visualizer] Error:', error);
          }
        },

        // Note: Mic level visualization is now handled by the 'mic-level-visualizer' A-Frame component
        // This ensures it works properly in VR mode with A-Frame's render loop
        updateMicLevel() {
          // Deprecated - using A-Frame component instead
          // The mic-level-visualizer component handles this in VR
        },

        setupUIListeners() {
          // Language buttons
          document.querySelectorAll('.lang-btn').forEach(btn => {
            btn.addEventListener('click', async (e) => {
              document.querySelectorAll('.lang-btn').forEach(b => b.classList.remove('active'));
              btn.classList.add('active');
              
              const oldLang = this.currentLanguage;
              this.currentLanguage = btn.dataset.lang;
              this.currentLanguageName = btn.dataset.name;
              
              // Update recognition system
              if (this.useVosk && oldLang !== this.currentLanguage) {
                const loadingOverlay = document.getElementById('loading-overlay');
                const progressFill = document.getElementById('progress-fill');
                const loadingStatus = document.getElementById('loading-status');
                
                loadingOverlay.classList.remove('hidden');
                
                await VoskRecognizer.switchLanguage(
                  this.currentLanguage,
                  (progress, status) => {
                    progressFill.style.width = progress + '%';
                    loadingStatus.textContent = status;
                  }
                );
                
                loadingOverlay.classList.add('hidden');
              } else if (this.recognition) {
                this.recognition.lang = this.currentLanguage;
              }
              
              // Update voice
              const langPrefix = this.currentLanguage.split('-')[0];
              this.selectedVoice = this.voices.find(v => v.lang.startsWith(langPrefix)) || this.voices[0];
              
              this.updateNPCName();
              this.currentPhraseIndex = 0;
              this.nextPhrase();
            });
          });

          // Scenario buttons
          document.querySelectorAll('.scenario-btn').forEach(btn => {
            btn.addEventListener('click', (e) => {
              document.querySelectorAll('.scenario-btn').forEach(b => b.classList.remove('active'));
              btn.classList.add('active');
              
              // Use changeScenario() for consistency and proper cleanup
              this.changeScenario(btn.dataset.scenario);
            });
          });
        },

        setupVRButtons() {
          setTimeout(() => {
            const repeatBtn = document.getElementById('repeat-btn');
            const nextBtn = document.getElementById('next-btn');
            const playPauseBtn = document.getElementById('play-pause-btn');
            
            console.log('[VR Buttons] Setting up button listeners...');
            
            // Note: The vr-button component handles click events
            // These are just for hover effects
            if (repeatBtn) {
              repeatBtn.addEventListener('mouseenter', () => repeatBtn.setAttribute('color', '#1976D2'));
              repeatBtn.addEventListener('mouseleave', () => repeatBtn.setAttribute('color', '#2196F3'));
            }
            
            if (nextBtn) {
              nextBtn.addEventListener('mouseenter', () => nextBtn.setAttribute('color', '#45a049'));
              nextBtn.addEventListener('mouseleave', () => nextBtn.setAttribute('color', '#4CAF50'));
            }
            
            if (playPauseBtn) {
              playPauseBtn.addEventListener('mouseenter', () => playPauseBtn.setAttribute('color', '#388E3C'));
              playPauseBtn.addEventListener('mouseleave', () => playPauseBtn.setAttribute('color', '#4CAF50'));
            }
            
            // Language selection in VR
            const langButtons = document.querySelectorAll('.lang-button');
            langButtons.forEach(btn => {
              btn.addEventListener('click', async () => {
                const lang = btn.getAttribute('data-lang');
                const langName = btn.getAttribute('data-name');
                
                langButtons.forEach(b => b.setAttribute('color', '#2196F3'));
                btn.setAttribute('color', '#4CAF50');
                
                const oldLang = this.currentLanguage;
                this.currentLanguage = lang;
                this.currentLanguageName = langName;
                
                if (this.useVosk && oldLang !== lang) {
                  this.updateVRText('vr-instruction-text', '‚è≥ Loading new language model...');
                  await VoskRecognizer.switchLanguage(lang, null);
                } else if (this.recognition) {
                  this.recognition.lang = lang;
                }
                
                const langPrefix = lang.split('-')[0];
                this.selectedVoice = this.voices.find(v => v.lang.startsWith(langPrefix)) || this.voices[0];
                
                this.updateNPCName();
                this.currentPhraseIndex = 0;
                this.nextPhrase();
              });
              
              btn.addEventListener('mouseenter', () => {
                if (btn.getAttribute('color') !== '#4CAF50') {
                  btn.setAttribute('color', '#1976D2');
                }
              });
              btn.addEventListener('mouseleave', () => {
                if (btn.getAttribute('color') !== '#4CAF50') {
                  btn.setAttribute('color', '#2196F3');
                }
              });
            });
            
            // Scenario selection in VR
            // Note: VR scenario buttons now use the vr-button component exclusively
            // The vr-button component calls changeScenario() which handles all logic
            const scenarioButtons = document.querySelectorAll('.scenario-button');
            scenarioButtons.forEach(btn => {
              // Only add hover effects, clicks are handled by vr-button component
              btn.addEventListener('mouseenter', () => {
                if (btn.getAttribute('color') !== '#4CAF50') {
                  btn.setAttribute('color', '#1976D2');
                }
              });
              btn.addEventListener('mouseleave', () => {
                if (btn.getAttribute('color') !== '#4CAF50') {
                  btn.setAttribute('color', '#2196F3');
                }
              });
            });
          }, 2000);
        },

        updateNPCName() {
          const npcNames = {
            'es-ES': 'Mar√≠a - Spanish Tutor',
            'fr-FR': 'Marie - French Tutor',
            'de-DE': 'Maria - German Tutor',
            'nl-NL': 'Maria - Dutch Tutor'
          };
          
          const nameTag = document.getElementById('npc-name');
          if (nameTag) {
            nameTag.setAttribute('value', npcNames[this.currentLanguage]);
          }
        },

        cleanupSceneResources(envEntity) {
          // Aggressively cleanup 3D models, textures, and geometries
          if (!envEntity) return;
          
          console.log('[Memory] Cleaning up scene resources for:', envEntity.id);
          
          // Find all GLTF models in this environment
          const gltfModels = envEntity.querySelectorAll('[gltf-model]');
          gltfModels.forEach(model => {
            try {
              // Remove the model from memory
              if (model.object3D) {
                model.object3D.traverse((node) => {
                  if (node.geometry) {
                    node.geometry.dispose();
                  }
                  if (node.material) {
                    if (Array.isArray(node.material)) {
                      node.material.forEach(mat => {
                        if (mat.map) mat.map.dispose();
                        if (mat.lightMap) mat.lightMap.dispose();
                        if (mat.bumpMap) mat.bumpMap.dispose();
                        if (mat.normalMap) mat.normalMap.dispose();
                        if (mat.specularMap) mat.specularMap.dispose();
                        if (mat.envMap) mat.envMap.dispose();
                        mat.dispose();
                      });
                    } else {
                      if (node.material.map) node.material.map.dispose();
                      if (node.material.lightMap) node.material.lightMap.dispose();
                      if (node.material.bumpMap) node.material.bumpMap.dispose();
                      if (node.material.normalMap) node.material.normalMap.dispose();
                      if (node.material.specularMap) node.material.specularMap.dispose();
                      if (node.material.envMap) node.material.envMap.dispose();
                      node.material.dispose();
                    }
                  }
                });
              }
              
              // Remove the GLTF model component
              if (model.components && model.components['gltf-model']) {
                model.removeAttribute('gltf-model');
              }
              
              console.log('[Memory] ‚úì Cleaned up model:', model.id);
            } catch (err) {
              console.warn('[Memory] Error cleaning up model:', err);
            }
          });
          
          console.log('[Memory] ‚úì Scene cleanup complete for:', envEntity.id);
        },

        switchEnvironment(scenario) {
          console.log('[Environment] Switching to scenario:', scenario);
          
          const envClassroom = document.getElementById('env-classroom');
          const envRestaurant = document.getElementById('env-restaurant');
          const envShopping = document.getElementById('env-shopping');
          const envDirections = document.getElementById('env-directions');
          
          if (!envClassroom || !envRestaurant || !envShopping || !envDirections) return;
          
          // Simply hide all environments and show the target one
          // DO NOT dispose of geometries/materials - they are needed when we return!
          console.log('[Environment] Switching environments (hide inactive, show active)...');
          
          // Hide all first
          envClassroom.setAttribute('visible', 'false');
          envRestaurant.setAttribute('visible', 'false');
          envShopping.setAttribute('visible', 'false');
          envDirections.setAttribute('visible', 'false');
          
          // Show the target environment
          if (scenario === 'directions') {
            envDirections.setAttribute('visible', 'true');
          } else if (scenario === 'shopping') {
            envShopping.setAttribute('visible', 'true');
          } else if (scenario === 'restaurant') {
            envRestaurant.setAttribute('visible', 'true');
          } else {
            envClassroom.setAttribute('visible', 'true');
          }
          
          console.log('[Environment] ‚úì Scenario switch complete');
        },

        nextPhrase() {
          if (this.isPaused) return;
          
          // Skip if we're changing language/scenario (prevents double calls)
          if (this.isChangingLanguage || this.isChangingScenario) {
            console.log('[App] Skipping nextPhrase - changing language/scenario');
            return;
          }
          
          // Clear the waitingForInteraction flag on first user interaction
          if (this.waitingForInteraction) {
            console.log('[App] First user interaction detected, starting experience');
            this.waitingForInteraction = false;
          }
          
          // CRITICAL: Stop any active recognition sessions first
          if (this.useVosk && this.isListening) {
            console.log('[App] Stopping Vosk before next phrase');
            VoskRecognizer.stop();
            this.isListening = false; // ‚Üê Sync the flag!
          } else if (!this.useVosk && this.recognition && this.isListening) {
            console.log('[App] Stopping Web Speech API before next phrase');
            try {
              this.recognition.stop();
              this.isListening = false;
            } catch (e) {
              console.warn('[App] Could not stop recognition:', e);
            }
          }
          
          const scenarioPhrases = this.phrases[this.currentScenario][this.currentLanguage];
          if (!scenarioPhrases || scenarioPhrases.length === 0) return;

          this.currentPhrase = scenarioPhrases[this.currentPhraseIndex];
          this.currentPhraseIndex = (this.currentPhraseIndex + 1) % scenarioPhrases.length;

          console.log('[App] Next phrase:', this.currentPhrase.text);
          
          this.displayPhrase(this.currentPhrase);
          this.npcSpeak(this.currentPhrase.text);
          
          // Delay removed - startListening will be called after TTS finishes
        },

        displayPhrase(phrase) {
          const phraseEl = document.getElementById('current-phrase');
          const phraseText = document.getElementById('phrase-text');
          const translation = document.getElementById('translation');
          
          phraseText.textContent = phrase.text;
          translation.textContent = phrase.translation;
          phraseEl.classList.add('active');
          
          this.updateVRText('vr-phrase-text', phrase.text);
          this.updateVRText('vr-translation-text', phrase.translation);
          this.updateVRText('vr-instruction-text', 'üé§ Listening... Speak now!');
          this.updateVRText('vr-heard-text', '');
        },

        updateVRText(elementId, text) {
          const el = document.getElementById(elementId);
          if (el) {
            el.setAttribute('value', text);
          }
        },

        togglePause() {
          this.isPaused = !this.isPaused;
          const playPauseText = document.getElementById('play-pause-text');
          
          if (this.isPaused) {
            if (this.useVosk) {
              VoskRecognizer.stop();
              this.isListening = false; // ‚Üê Sync the flag!
            } else if (this.recognition && this.isListening) {
              try {
                this.recognition.stop();
                this.isListening = false;
              } catch (e) {}
            }
            
            if (this.synthesis.speaking) {
              this.synthesis.cancel();
            }
            
            playPauseText.setAttribute('value', '‚ñ∂Ô∏è PLAY');
            this.updateVRText('vr-instruction-text', '‚è∏Ô∏è PAUSED');
          } else {
            playPauseText.setAttribute('value', '‚è∏Ô∏è PAUSE');
            
            if (this.currentPhrase) {
              this.displayPhrase(this.currentPhrase);
              this.npcSpeak(this.currentPhrase.text);
              // npcSpeak will handle startListening via onend callback
            } else {
              this.nextPhrase();
            }
          }
        },

        npcSpeak(text) {
          if (this.isPaused) return;
          
          // Prevent overlapping audio (debounce)
          if (this.isSpeaking) {
            console.log('[NPC Speak] ‚ö†Ô∏è Already speaking, ignoring duplicate call');
            return;
          }
          
          console.log('[NPC Speak] Attempting to speak:', text);
          console.log('[NPC Speak] Current language:', this.currentLanguage, 'Scenario:', this.currentScenario);
          
          // Set speaking flag
          this.isSpeaking = true;
          
          // Try to use audio file first (Option A: MP3 first, TTS fallback)
          if (this.currentPhrase && this.currentPhrase.audio) {
            const langCode = this.currentLanguage.split('-')[0]; // 'es-ES' -> 'es'
            const audioPath = `assets/audio/${langCode}/${this.currentScenario}/${this.currentPhrase.audio}`;
            
            console.log('[NPC Speak] Trying audio file:', audioPath);
            
            const audio = new Audio(audioPath);
            this.currentAudio = audio; // Store reference for cancellation
            
            // Don't show speech bubble for audio files - only update instruction text
            this.updateVRText('vr-instruction-text', 'üîä NPC is speaking...');
            
            audio.onloadeddata = () => {
              console.log('[NPC Speak] ‚úì Audio file loaded successfully:', audioPath);
            };
            
            audio.onplay = () => {
              console.log('[NPC Speak] ‚úì Audio playback started');
              this.updateVRText('vr-instruction-text', 'üîä Listening to NPC...');
            };
            
            audio.onended = () => {
              console.log('[NPC Speak] ‚úì Audio playback finished');
              this.isSpeaking = false; // Clear speaking flag
              this.currentAudio = null; // Clear reference
              // Reduced delay from 800ms to 300ms for faster user experience
              setTimeout(() => {
                // Start listening after audio completes
                if (!this.isPaused) {
                  console.log('[NPC Speak] ‚úì Starting STT after audio finished');
                  this.startListening();
                }
              }, 300);
            };
            
            audio.onerror = (e) => {
              console.warn('[NPC Speak] ‚ö†Ô∏è Audio file failed to load, falling back to TTS:', audioPath);
              console.warn('[NPC Speak] Error details:', e);
              this.isSpeaking = false; // Clear speaking flag
              this.currentAudio = null; // Clear reference
              
              // Fallback to TTS
              this.npcSpeakTTS(text);
            };
            
            // Attempt to play
            audio.play().catch(err => {
              console.warn('[NPC Speak] ‚ö†Ô∏è Audio playback failed, falling back to TTS:', err);
              this.isSpeaking = false; // Clear speaking flag
              this.currentAudio = null; // Clear reference
              this.npcSpeakTTS(text);
            });
            
            return; // Exit early, audio will handle the rest
          }
          
          // No audio file available, use TTS
          console.log('[NPC Speak] No audio file specified, using TTS');
          this.npcSpeakTTS(text);
        },
        
        npcSpeakTTS(text) {
          console.log('[NPC Speak TTS] Using speech synthesis for:', text);
          console.log('[NPC Speak TTS] User Agent:', navigator.userAgent);
          console.log('[NPC Speak TTS] Audio unlocked?:', this.audioUnlocked);
          console.log('[NPC Speak TTS] Synthesis available?:', !!this.synthesis);
          
          // Check if synthesis is available
          if (!this.synthesis) {
            console.warn('[NPC Speak TTS] ‚ùå Speech Synthesis not available - showing text only');
            this.showSpeechBubble(text);
            this.updateVRText('vr-instruction-text', 'üìù Read the phrase above and speak it!');
            this.updateVRText('vr-phrase-text', `Say: "${text}"`);
            
            // Still start listening after a delay (silent mode)
            setTimeout(() => {
              this.hideSpeechBubble();
              this.isSpeaking = false; // Clear speaking flag
              this.startListening(); // ‚Üê CRITICAL: Start listening even without TTS
            }, 3000);
            
            return;
          }
          
          console.log('[NPC Speak TTS] Available voices:', this.synthesis.getVoices().length);
          
          // Unlock audio on first user interaction (Quest requirement)
          if (!this.audioUnlocked) {
            console.log('[NPC Speak TTS] Unlocking audio context...');
            this.audioUnlocked = true;
            
            // Quest-specific: Resume audio context if suspended
            if (window.AudioContext || window.webkitAudioContext) {
              const AudioContextClass = window.AudioContext || window.webkitAudioContext;
              if (!this.audioContext) {
                this.audioContext = new AudioContextClass();
              }
              if (this.audioContext.state === 'suspended') {
                console.log('[NPC Speak TTS] Resuming suspended audio context...');
                this.audioContext.resume().then(() => {
                  console.log('[NPC Speak TTS] ‚úì Audio context resumed:', this.audioContext.state);
                });
              }
            }
            
            // Create a silent audio to unlock the audio context
            const silentAudio = new Audio();
            silentAudio.src = 'data:audio/mp3;base64,SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU4Ljc2LjEwMAAAAAAAAAAAAAAA//tQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWGluZwAAAA8AAAACAAADhQCAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICA//////////////////////////////////////////////////////////////////8AAAAATGF2YzU4LjEzAAAAAAAAAAAAAAAAJAAAAAAAAAAAA4X/////////////////////////////////////////////////';
            silentAudio.play().then(() => {
              console.log('[NPC Speak TTS] ‚úì Silent audio played successfully');
            }).catch(e => {
              console.log('[Audio] Unlock attempt error:', e);
            });
          }
          
          this.synthesis.cancel();
          this.showSpeechBubble(text);
          this.updateVRText('vr-instruction-text', 'üîä NPC is speaking...');

          setTimeout(() => {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = this.currentLanguage;
            utterance.rate = 0.85;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            if (this.selectedVoice) {
              utterance.voice = this.selectedVoice;
              console.log('[NPC Speak TTS] Using voice:', this.selectedVoice.name);
            } else {
              console.warn('[NPC Speak TTS] No voice selected!');
              // Try to get voices again
              const voices = this.synthesis.getVoices();
              if (voices.length > 0) {
                this.selectedVoice = voices.find(v => v.lang.startsWith(this.currentLanguage.substring(0, 2))) || voices[0];
                utterance.voice = this.selectedVoice;
                console.log('[NPC Speak TTS] Auto-selected voice:', this.selectedVoice.name);
              }
            }
            
            let hasStarted = false;
            
            utterance.onstart = () => {
              hasStarted = true;
              console.log('[NPC Speak TTS] ‚úì Audio started playing');
              this.updateVRText('vr-instruction-text', 'üîä Listening to NPC...');
            };
            
            utterance.onend = () => {
              console.log('[NPC Speak TTS] Audio finished. hasStarted:', hasStarted);
              if (!hasStarted) {
                console.error('[NPC] ‚ùå Audio blocked by browser - try clicking REPEAT button');
                this.updateVRText('vr-instruction-text', '‚ùå Audio blocked - click REPEAT');
              }
              this.isSpeaking = false; // Clear speaking flag
              // Reduced delay from 800ms to 300ms for faster user experience
              setTimeout(() => {
                this.hideSpeechBubble();
                
                // CRITICAL: Start listening ONLY after TTS completes
                // Add delay to ensure audio output fully stops and prevent echo
                if (!this.isPaused) {
                  console.log('[NPC Speak TTS] ‚úì Starting STT after TTS finished');
                  this.startListening();
                }
              }, 300);
            };
            
            utterance.onerror = (event) => {
              console.error('[NPC Speak TTS] ‚ùå Error:', event.error, event);
              this.updateVRText('vr-instruction-text', '‚ùå Speech error: ' + event.error);
              this.isSpeaking = false; // Clear speaking flag
              
              // Still start listening even if TTS fails
              setTimeout(() => {
                if (!this.isPaused) {
                  this.startListening();
                }
              }, 500);
            };
            
            console.log('[NPC Speak TTS] Calling synthesis.speak()');
            this.synthesis.speak(utterance);
            
            // Check if it's actually speaking
            setTimeout(() => {
              console.log('[NPC Speak TTS] Speaking status:', this.synthesis.speaking, 'Pending:', this.synthesis.pending);
              if (!this.synthesis.speaking && !this.synthesis.pending) {
                console.error('[NPC Speak TTS] ‚ùå Speech synthesis not working!');
                this.updateVRText('vr-instruction-text', '‚ùå Speech not working - check console');
              }
            }, 200);
          }, 100);
        },

        showSpeechBubble(text) {
          const bubble = document.getElementById('speech-bubble');
          const bubbleText = document.getElementById('bubble-text');
          
          if (bubble && bubbleText) {
            bubbleText.setAttribute('value', text);
            bubble.setAttribute('visible', 'true');
          }
        },

        hideSpeechBubble() {
          const bubble = document.getElementById('speech-bubble');
          if (bubble) {
            bubble.setAttribute('visible', 'false');
          }
        },

        startListening() {
          if (this.isPaused) return;
          
          if (this.useVosk) {
            // Double-check Vosk state before starting
            if (this.isListening || VoskRecognizer.isListening) {
              console.warn('[STT] Vosk already listening (App:', this.isListening, 'Vosk:', VoskRecognizer.isListening, ') - skipping start');
              // Synchronize flags to ensure consistency
              this.isListening = VoskRecognizer.isListening;
              return;
            }
            
            console.log('[STT] Starting Vosk...');
            VoskRecognizer.start();
            this.isListening = true;
            this.updateVRText('vr-instruction-text', 'üé§ SPEAK NOW!');
          } else {
            if (!this.recognition) return;
            
            // Prevent duplicate instances
            if (this.isListening) {
              console.warn('[STT] Web Speech API already listening, skipping start');
              return;
            }

            try {
              this.recognition.start();
              console.log('[STT] Web Speech API started');
            } catch (e) {
              console.warn('[Speech] Could not start:', e);
            }
          }
        },

        checkAnswer(userSaid, confidence) {
          if (!this.currentPhrase) return;

          const expected = this.currentPhrase.text.toLowerCase();
          const spoken = userSaid.toLowerCase();

          console.log('[Check] Expected:', expected);
          console.log('[Check] Spoken:', spoken);

          // Reset heard text color to white for final result
          const heardEl = document.getElementById('vr-heard-text');
          if (heardEl) {
            heardEl.setAttribute('color', '#FFFFFF');
          }

          // IMPROVED: Check if spoken text CONTAINS the expected phrase (handles TTS echo and duplicates)
          // Remove punctuation for comparison
          const expectedNoPunct = expected.replace(/[¬ø¬°?!.,]/g, '').trim();
          const spokenNoPunct = spoken.replace(/[¬ø¬°?!.,]/g, '').trim();
          
          // Check if expected phrase is contained in spoken text
          const isContained = spokenNoPunct.includes(expectedNoPunct);
          
          // Also check similarity for partial credit
          const similarity = this.calculateSimilarity(spokenNoPunct, expectedNoPunct);
          console.log('[Check] Contains expected?:', isContained);
          console.log('[Check] Similarity:', similarity);

          let feedback, points, className;

          if (isContained || similarity > 0.80) {
            feedback = '¬°Excelente! üéâ<br>Perfect!';
            points = 100;
            className = 'success';
            this.awardPoints(points);
            
            this.updateVRText('vr-instruction-text', '‚úÖ Perfect! Next phrase...');
            
            const timeoutId = setTimeout(() => {
              if (!this.isPaused) {
                this.nextPhrase();
              }
            }, 2000);
            this.pendingTimeouts.push(timeoutId);
          } else if (similarity > 0.60) {
            feedback = '¬°Bien! üëç<br>Good, try again';
            points = 50;
            className = 'warning';
            this.awardPoints(points);
            
            this.updateVRText('vr-instruction-text', '‚ö†Ô∏è Good! Try the exact phrase...');
            
            const timeoutId = setTimeout(() => {
              this.npcSpeak(this.currentPhrase.text);
              // npcSpeak will handle startListening via onend callback
            }, 2000);
            this.pendingTimeouts.push(timeoutId);
          } else if (similarity > 0.45) {
            feedback = 'Casi... ü§î<br>Almost!';
            points = 25;
            className = 'warning';
            this.awardPoints(points);
            
            this.updateVRText('vr-instruction-text', '‚ö†Ô∏è Close! Listen again...');
            
            const timeoutId = setTimeout(() => {
              this.npcSpeak(this.currentPhrase.text);
              // npcSpeak will handle startListening via onend callback
            }, 2000);
            this.pendingTimeouts.push(timeoutId);
          } else {
            feedback = `‚ùå No coincide<br>Try: "${this.currentPhrase.text}"`;
            points = 0;
            className = 'error';
            
            this.updateVRText('vr-instruction-text', '‚ùå Wrong. Listen carefully...');
            
            const timeoutId = setTimeout(() => {
              this.npcSpeak(this.currentPhrase.text);
              // npcSpeak will handle startListening via onend callback
            }, 2500);
            this.pendingTimeouts.push(timeoutId);
          }

          this.showFeedback(feedback, className);
        },

        calculateSimilarity(str1, str2) {
          str1 = str1.toLowerCase().replace(/[¬ø?¬°!.,]/g, '').trim();
          str2 = str2.toLowerCase().replace(/[¬ø?¬°!.,]/g, '').trim();

          if (str1 === str2) return 1.0;

          const distance = this.levenshteinDistance(str1, str2);
          const maxLength = Math.max(str1.length, str2.length);
          
          if (maxLength === 0) return 1.0;
          
          return 1.0 - (distance / maxLength);
        },

        levenshteinDistance(str1, str2) {
          // Pre-allocate matrix rows to reduce allocations
          const len1 = str1.length;
          const len2 = str2.length;
          
          // Early exit for edge cases
          if (len1 === 0) return len2;
          if (len2 === 0) return len1;
          
          // Use single array with rolling window instead of 2D matrix
          // This reduces memory from O(n*m) to O(min(n,m))
          let prevRow = new Array(len1 + 1);
          let currRow = new Array(len1 + 1);
          
          // Initialize first row
          for (let j = 0; j <= len1; j++) {
            prevRow[j] = j;
          }
          
          // Calculate distance using rolling arrays
          for (let i = 1; i <= len2; i++) {
            currRow[0] = i;
            
            for (let j = 1; j <= len1; j++) {
              if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
                currRow[j] = prevRow[j - 1];
              } else {
                currRow[j] = Math.min(
                  prevRow[j - 1] + 1,  // substitution
                  currRow[j - 1] + 1,  // insertion
                  prevRow[j] + 1       // deletion
                );
              }
            }
            
            // Swap rows for next iteration
            const temp = prevRow;
            prevRow = currRow;
            currRow = temp;
          }
          
          return prevRow[len1];
        },
        
        clearPendingTimeouts() {
          console.log('[App] Clearing', this.pendingTimeouts.length, 'pending timeouts');
          this.pendingTimeouts.forEach(id => clearTimeout(id));
          this.pendingTimeouts = [];
        },
        
        async changeLanguage(lang, langName) {
          console.log('[Language App] Changing language to:', lang, langName);
          
          // Set flag to prevent race conditions
          this.isChangingLanguage = true;
          
          // Clear ALL pending operations
        this.clearPendingTimeouts();
        
        // CRITICAL: Stop any ongoing audio playback first!
        if (this.currentAudio) {
          console.log('[Language App] Aborting current audio playback for language change');
          this.currentAudio.pause();
          this.currentAudio.currentTime = 0;
          this.currentAudio = null;
        }
        if (this.isSpeaking) {
          console.log('[Language App] Stopping ongoing audio playback for language change');
          this.isSpeaking = false; // Reset the flag to allow new audio
        }
        
        const oldLang = this.currentLanguage;
        this.currentLanguage = lang;
        this.currentLanguageName = langName || lang;
        
        // Cancel any ongoing speech AND stop recognition
        if (this.synthesis) {
          this.synthesis.cancel();
        }
        
        // Stop recognition immediately - force stop regardless of isListening state
        if (this.useVosk) {
          console.log('[Language App] Stopping Vosk for language change (forced)');
          VoskRecognizer.stop();
          this.isListening = false;
        } else if (!this.useVosk && this.recognition) {
          try {
            this.recognition.stop();
            this.isListening = false;
          } catch (e) {}
        }
          
          // Ensure app is not paused when changing language
          if (this.isPaused) {
            console.log('[Language App] Unpausing app for language change');
            this.isPaused = false;
            const playPauseText = document.getElementById('play-pause-text');
            if (playPauseText) {
              playPauseText.setAttribute('value', '‚è∏Ô∏è PAUSE');
            }
          }
          
          // Update voices
          this.loadVoices();
          
          // If using Vosk, reload model
          if (this.useVosk && oldLang !== lang) {
            this.updateVRText('vr-instruction-text', '‚è≥ Loading new language model...');
            try {
              await VoskRecognizer.switchLanguage(lang, (progress, status) => {
                console.log('[Vosk] Language switch:', status, progress + '%');
              });
              
              // Update analyser reference for mic level bar
              if (VoskRecognizer.analyser) {
                console.log('[Language App] Updating analyser reference after language switch');
                this.analyser = VoskRecognizer.analyser;
                this.audioContext = VoskRecognizer.audioContext;
              }
              
              this.updateVRText('vr-instruction-text', '‚úÖ Language changed!');
            } catch (error) {
              console.error('[Language App] Language switch error:', error);
              this.updateVRText('vr-instruction-text', '‚ùå Language switch failed');
            }
          } else if (!this.useVosk && this.recognition) {
            // Update Web Speech API language
            this.recognition.lang = lang;
          }
          
          // Restart with new language
          this.currentPhraseIndex = 0;
          
          // Update grammar hints for new language
          if (!this.useVosk && this.recognition) {
            this.updateSpeechGrammar();
          }
          
          // Clear flag and start next phrase
          this.isChangingLanguage = false;
          this.nextPhrase();
        },
        
        changeScenario(scenario) {
          // Prevent multiple simultaneous scenario changes (debounce)
          if (this.isChangingScenario) {
            console.log('[Language App] ‚ö†Ô∏è Scenario change already in progress, ignoring duplicate call');
            return;
          }
          
          console.log('[Language App] Changing scenario to:', scenario);
          
          // Set flag to prevent race conditions
          this.isChangingScenario = true;
          
        // Clear ALL pending operations
        this.clearPendingTimeouts();
        
        // CRITICAL: Stop any ongoing audio playback first!
        if (this.currentAudio) {
          console.log('[Language App] Aborting current audio playback for scenario change');
          this.currentAudio.pause();
          this.currentAudio.currentTime = 0;
          this.currentAudio = null;
        }
        if (this.isSpeaking) {
          console.log('[Language App] Stopping ongoing audio playback for scenario change');
          this.isSpeaking = false; // Reset the flag to allow new audio
        }
        
        // Cancel any ongoing speech AND stop recognition
        if (this.synthesis) {
          this.synthesis.cancel();
        }
        
        // Stop recognition immediately and cleanup audio resources
        // Force stop Vosk regardless of isListening flag state
        if (this.useVosk) {
          console.log('[Language App] Stopping Vosk for scenario change (forced)');
          VoskRecognizer.stop();
          this.isListening = false;
        } else if (!this.useVosk && this.recognition) {
          try {
            this.recognition.stop();
            this.isListening = false;
          } catch (e) {}
        }
          
          // Ensure app is not paused when changing scenario
          if (this.isPaused) {
            console.log('[Language App] Unpausing app for scenario change');
            this.isPaused = false;
            const playPauseText = document.getElementById('play-pause-text');
            if (playPauseText) {
              playPauseText.setAttribute('value', '‚è∏Ô∏è PAUSE');
            }
          }
          
          this.currentScenario = scenario;
          this.currentPhraseIndex = 0;
          
          // Switch environment (simple hide/show, no disposal)
          this.switchEnvironment(scenario);
          
          // Update grammar hints for new scenario
          if (!this.useVosk && this.recognition) {
            this.updateSpeechGrammar();
          } else if (this.useVosk && VoskRecognizer.recognizer) {
            VoskRecognizer.updateVoskGrammar();
          }
          
          // Clear flag and start next phrase
          this.isChangingScenario = false;
          this.nextPhrase();
        },

        awardPoints(points) {
          this.score += points;
          document.getElementById('score').textContent = `Score: ${this.score} üåü`;
          this.updateVRText('vr-score-text', `Score: ${this.score} üåü`);
        },

        showFeedback(message, className) {
          const banner = document.getElementById('feedback-banner');
          banner.innerHTML = message;
          banner.className = className;
          banner.classList.add('show');

          setTimeout(() => {
            banner.classList.remove('show');
          }, 2000);
        },

        updateStatus(message) {
          document.getElementById('status').textContent = message;
        },

        updateSpeechStatus(message, className) {
          const el = document.getElementById('speech-status');
          el.textContent = message;
          el.className = 'status ' + (className || '');
        }
      };

      // ========================================
      // A-FRAME COMPONENTS (Same as index.html)
      // ========================================
      
      AFRAME.registerComponent('ui-toggle-controller', {
        init: function() {
          this.uiVisible = true;
          this.lastAButtonPress = 0;
          
          // A button to toggle UI with debouncing (same pattern as spaceshooter.html)
          this.el.sceneEl.addEventListener('abuttondown', () => {
            const now = Date.now();
            if (now - this.lastAButtonPress < 500) return; // 500ms debounce
            this.lastAButtonPress = now;
            console.log('[UI Toggle] A button pressed');
            this.toggleUI();
          });
        },
        
        toggleUI: function() {
          this.uiVisible = !this.uiVisible;
          console.log('[UI Toggle] UI now:', this.uiVisible ? 'visible' : 'hidden');
          
          const vrUIPanel = document.getElementById('vr-ui-panel');
          const vrLanguagePanel = document.getElementById('vr-language-panel');
          const vrScenarioPanel = document.getElementById('vr-scenario-panel');
          
          if (vrUIPanel) vrUIPanel.setAttribute('visible', this.uiVisible);
          if (vrLanguagePanel) vrLanguagePanel.setAttribute('visible', this.uiVisible);
          if (vrScenarioPanel) vrScenarioPanel.setAttribute('visible', this.uiVisible);
        }
      });
      
      // VR Button Click Handler Component (Quest-compatible)
      AFRAME.registerComponent('vr-button', {
        schema: {
          action: { type: 'string', default: '' },
          lang: { type: 'string', default: '' },
          scenario: { type: 'string', default: '' }
        },
        
        init: function() {
          this.onClick = this.onClick.bind(this);
          this.onHover = this.onHover.bind(this);
          this.onLeave = this.onLeave.bind(this);
          
          this.el.addEventListener('click', this.onClick);
          this.el.addEventListener('mouseenter', this.onHover);
          this.el.addEventListener('mouseleave', this.onLeave);
          
          this.originalColor = this.el.getAttribute('color');
          
          // Add debouncing to prevent double-clicks in VR
          this.lastClickTime = 0;
          this.clickDebounceMs = 500; // 500ms debounce for VR controller double-clicks
          
          // Cache button queries for performance (avoid repeated DOM queries)
          this.langButtonsCache = null;
          this.scenarioButtonsCache = null;
          
          // Also handle data attributes for backwards compatibility
          if (!this.data.lang && this.el.getAttribute('data-lang')) {
            this.data.lang = this.el.getAttribute('data-lang');
          }
          if (!this.data.scenario && this.el.getAttribute('data-scenario')) {
            this.data.scenario = this.el.getAttribute('data-scenario');
          }
        },
        
        onClick: function() {
          // Debounce to prevent double-clicks from VR controllers
          const now = Date.now();
          if (now - this.lastClickTime < this.clickDebounceMs) {
            console.log('[VR Button] ‚ö†Ô∏è Ignoring duplicate click (debounced)');
            return;
          }
          this.lastClickTime = now;
          
          console.log('[VR Button] Clicked:', this.data.action || this.data.lang || this.data.scenario);
          
          // Handle action buttons
          if (this.data.action === 'repeat') {
            console.log('[VR Button] Repeat - current phrase:', LanguageApp.currentPhrase);
            if (LanguageApp.currentPhrase && !LanguageApp.isPaused) {
              LanguageApp.npcSpeak(LanguageApp.currentPhrase.text);
            }
          } else if (this.data.action === 'next') {
            console.log('[VR Button] Next - paused?', LanguageApp.isPaused);
            if (!LanguageApp.isPaused) {
              LanguageApp.nextPhrase();
            }
          } else if (this.data.action === 'play-pause') {
            console.log('[VR Button] Toggle pause - current state:', LanguageApp.isPaused);
            LanguageApp.togglePause();
          }
          
          // Handle language buttons
          else if (this.data.lang) {
            console.log('[VR Button] Language selected:', this.data.lang);
            const langName = this.el.getAttribute('data-name') || this.data.lang;
            LanguageApp.changeLanguage(this.data.lang, langName);
            
            // Update button colors (use cached query)
            if (!this.langButtonsCache) {
              this.langButtonsCache = document.querySelectorAll('.lang-button');
            }
            this.langButtonsCache.forEach(btn => {
              btn.setAttribute('color', '#2196F3');
            });
            this.el.setAttribute('color', '#4CAF50');
          }
          
          // Handle scenario buttons
          else if (this.data.scenario) {
            console.log('[VR Button] Scenario selected:', this.data.scenario);
            LanguageApp.changeScenario(this.data.scenario);
            
            // Update button colors (use cached query)
            if (!this.scenarioButtonsCache) {
              this.scenarioButtonsCache = document.querySelectorAll('.scenario-button');
            }
            this.scenarioButtonsCache.forEach(btn => {
              btn.setAttribute('color', '#2196F3');
            });
            this.el.setAttribute('color', '#4CAF50');
          }
        },
        
        onHover: function() {
          // Darken the button color on hover
          const currentColor = this.el.getAttribute('color');
          if (currentColor === '#2196F3') {
            this.el.setAttribute('color', '#1976D2');
          } else if (currentColor === '#4CAF50') {
            this.el.setAttribute('color', '#45a049');
          }
        },
        
        onLeave: function() {
          // Restore original color
          this.el.setAttribute('color', this.originalColor);
        },
        
        remove: function() {
          this.el.removeEventListener('click', this.onClick);
          this.el.removeEventListener('mouseenter', this.onHover);
          this.el.removeEventListener('mouseleave', this.onLeave);
        }
      });
      
      // Mic Level Visualizer Component
      AFRAME.registerComponent('mic-level-visualizer', {
        init: function() {
          console.log('[Mic Level Visualizer] Component initialized');
          this.maxWidth = 1.5; // Maximum bar width
          this.analyser = null; // Will be set by VoskRecognizer or LanguageApp
          this.frameCount = 0;
          this.dataArray = null; // Pre-allocated array for performance
          this.lastColor = null; // Cache last color to avoid redundant setAttribute
          this.lastWidth = 0; // Cache last width
          this.lastPosX = 0; // Cache last position
        },
        
        tick: function() {
          this.frameCount++;
          
          if (!this.analyser) {
            // Log every 300 frames (~5 seconds at 60fps) if no analyser found
            if (this.frameCount % 300 === 0) {
              console.warn('[Mic Level Visualizer] No analyser set yet (frame', this.frameCount, ')');
            }
            return; // No analyser available yet
          }
          
          // Allocate dataArray once when analyser becomes available
          if (!this.dataArray) {
            this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
            console.log('[Mic Level Visualizer] ‚úì Pre-allocated dataArray (size:', this.analyser.frequencyBinCount, ') - eliminates per-frame allocations');
          }
          
          // Get frequency data (reuses pre-allocated array)
          this.analyser.getByteFrequencyData(this.dataArray);
          
          // Calculate average level
          let sum = 0;
          for (let i = 0; i < this.dataArray.length; i++) {
            sum += this.dataArray[i];
          }
          const average = sum / this.dataArray.length;
          const normalized = average / 255; // 0.0 to 1.0
          
          // Update bar width (only if changed significantly)
          const barWidth = normalized * this.maxWidth;
          if (Math.abs(barWidth - this.lastWidth) > 0.01) { // 1% threshold
            this.el.setAttribute('width', barWidth);
            this.lastWidth = barWidth;
            
            // Update bar position (expand from left)
            const barX = -0.75 + (barWidth / 2);
            if (Math.abs(barX - this.lastPosX) > 0.005) { // 0.5% threshold
              this.el.object3D.position.x = barX;
              this.lastPosX = barX;
            }
          }
          
          // Update bar color based on level (only if changed)
          let newColor;
          if (normalized > 0.3) {
            newColor = '#4CAF50'; // Green - good level
          } else if (normalized > 0.1) {
            newColor = '#FFC107'; // Yellow - low level
          } else {
            newColor = '#666666'; // Gray - very low/silent
          }
          
          if (newColor !== this.lastColor) {
            this.el.setAttribute('color', newColor);
            this.lastColor = newColor;
          }
          
          // Log mic activity every 120 frames (~2 seconds) - reduced logging
          if (this.frameCount % 120 === 0 && normalized > 0.05) {
            console.log('[Mic Level Visualizer] Level:', (normalized * 100).toFixed(1) + '%');
          }
        }
      });
      
      AFRAME.registerComponent('raycaster-debug', {
        init: function() {
          const handName = this.el.id;
          
          console.log(`[${handName}] Raycaster debug component initialized`);
          
          // Log when controller is connected
          this.el.addEventListener('controllerconnected', (evt) => {
            console.log(`[${handName}] Controller connected:`, evt.detail.name);
          });
          
          // Log raycaster component initialization
          setTimeout(() => {
            const raycaster = this.el.components.raycaster;
            if (raycaster) {
              console.log(`[${handName}] Raycaster component found:`, raycaster.data);
            } else {
              console.error(`[${handName}] NO raycaster component!`);
            }
          }, 1000);
          
          this.el.addEventListener('raycaster-intersection', (evt) => {
            console.log(`[${handName}] Raycaster Hit:`, evt.detail.els.map(el => el.id || el.className));
          });
          
          this.el.addEventListener('raycaster-intersection-cleared', () => {
            console.log(`[${handName}] Raycaster cleared`);
          });
          
          this.el.addEventListener('triggerdown', () => {
            console.log(`[${handName}] Trigger pressed`);
            // Manually check what's under the raycaster
            const raycaster = this.el.components.raycaster;
            if (raycaster && raycaster.intersectedEls) {
              console.log(`[${handName}] Currently intersecting:`, raycaster.intersectedEls.map(el => el.id || el.className));
            }
          });
          
          this.el.addEventListener('triggerup', () => {
            console.log(`[${handName}] Trigger released`);
          });
        }
      });
      
      AFRAME.registerComponent('vr-locomotion', {
        schema: {
          rotationSpeed: { type: 'number', default: 2.0 }
        },

        init: function() {
          this.npcRotationY = 0;
          this.playerRotationY = 0;
          this.thumbstickRotation = { right: 0 };
          this.npcTutor = null;
          
          setTimeout(() => {
            this.npcTutor = document.querySelector('#npc-tutor');
          }, 100);
          
          // Hide hand controller models (aggressive hiding for Quest)
          const hideHandModels = () => {
            const leftHand = document.querySelector('#left-hand');
            const rightHand = document.querySelector('#right-hand');
            
            if (leftHand && leftHand.object3D) {
              leftHand.object3D.visible = false; // Hide entire object3D
              leftHand.object3D.traverse((node) => {
                if (node.isMesh) {
                  node.visible = false;
                  // Also hide material to be extra sure
                  if (node.material) {
                    node.material.visible = false;
                  }
                }
              });
            }
            if (rightHand && rightHand.object3D) {
              rightHand.object3D.visible = false; // Hide entire object3D
              rightHand.object3D.traverse((node) => {
                if (node.isMesh) {
                  node.visible = false;
                  // Also hide material to be extra sure
                  if (node.material) {
                    node.material.visible = false;
                  }
                }
              });
            }
          };
          
          // Run immediately and then again after delays to catch late-loading models
          setTimeout(hideHandModels, 100);
          setTimeout(hideHandModels, 500);
          setTimeout(hideHandModels, 1000);
          setTimeout(hideHandModels, 2000);
          
          this.el.sceneEl.addEventListener('thumbstickmoved', (evt) => {
            if (!evt.target || !evt.target.object3D) return;
            const hand = evt.target;
            this.handleThumbstick(hand, evt.detail);
          });
        },
        
        handleThumbstick: function(hand, detail) {
          const isLeft = hand.id === 'left-hand';
          if (!isLeft && Math.abs(detail.x) > 0.1) {
            this.thumbstickRotation.right = -detail.x;
          } else if (!isLeft) {
            this.thumbstickRotation.right = 0;
          }
        },

        tick: function(time, deltaTime) {
          const dt = Math.min(deltaTime / 1000, 0.1);
          const rotationInput = this.thumbstickRotation.right;
          
          if (Math.abs(rotationInput) > 0.1) {
            // Rotate the player rig
            this.playerRotationY += rotationInput * this.data.rotationSpeed * dt;
            this.el.object3D.rotation.y = this.playerRotationY;
            
            // Also rotate NPC to match
            this.npcRotationY += rotationInput * this.data.rotationSpeed * dt;
          }
          
          if (this.npcTutor && this.npcTutor.components['mixamo-body']) {
            this.npcTutor.components['mixamo-body'].manualRotationY = this.npcRotationY;
          }
        }
      });

      AFRAME.registerComponent('language-npc', {
        init: function() {
          console.log('[NPC] Initialized');
        }
      });

      // Mixamo VR Body Component (from body-rigged.html)
      AFRAME.registerComponent('mixamo-body', {
        schema: {
          isMirror: { type: 'boolean', default: false },
          color: { type: 'color', default: '#4A90E2' },
          modelPath: { type: 'string', default: 'BoltVR/assets/Y Bot.fbx' }
        },

        init: function() {
          this.camera = document.querySelector('#camera');
          this.leftController = document.querySelector('#left-hand');
          this.rightController = document.querySelector('#right-hand');
          this.rig = document.querySelector('#rig');
          
          this.skeleton = null;
          this.bones = {};
          this.model = null;
          this.modelLoaded = false;
          
          // Mixamo bone names
          this.boneNames = {
            hips: 'mixamorigHips',
            spine: 'mixamorigSpine',
            spine1: 'mixamorigSpine1',
            spine2: 'mixamorigSpine2',
            neck: 'mixamorigNeck',
            head: 'mixamorigHead',
            leftShoulder: 'mixamorigLeftShoulder',
            leftArm: 'mixamorigLeftArm',
            leftForeArm: 'mixamorigLeftForeArm',
            leftHand: 'mixamorigLeftHand',
            rightShoulder: 'mixamorigRightShoulder',
            rightArm: 'mixamorigRightArm',
            rightForeArm: 'mixamorigRightForeArm',
            rightHand: 'mixamorigRightHand',
            // Finger bones - Left hand
            leftHandThumb1: 'mixamorigLeftHandThumb1',
            leftHandThumb2: 'mixamorigLeftHandThumb2',
            leftHandThumb3: 'mixamorigLeftHandThumb3',
            leftHandIndex1: 'mixamorigLeftHandIndex1',
            leftHandIndex2: 'mixamorigLeftHandIndex2',
            leftHandIndex3: 'mixamorigLeftHandIndex3',
            leftHandMiddle1: 'mixamorigLeftHandMiddle1',
            leftHandMiddle2: 'mixamorigLeftHandMiddle2',
            leftHandMiddle3: 'mixamorigLeftHandMiddle3',
            leftHandRing1: 'mixamorigLeftHandRing1',
            leftHandRing2: 'mixamorigLeftHandRing2',
            leftHandRing3: 'mixamorigLeftHandRing3',
            leftHandPinky1: 'mixamorigLeftHandPinky1',
            leftHandPinky2: 'mixamorigLeftHandPinky2',
            leftHandPinky3: 'mixamorigLeftHandPinky3',
            // Finger bones - Right hand
            rightHandThumb1: 'mixamorigRightHandThumb1',
            rightHandThumb2: 'mixamorigRightHandThumb2',
            rightHandThumb3: 'mixamorigRightHandThumb3',
            rightHandIndex1: 'mixamorigRightHandIndex1',
            rightHandIndex2: 'mixamorigRightHandIndex2',
            rightHandIndex3: 'mixamorigRightHandIndex3',
            rightHandMiddle1: 'mixamorigRightHandMiddle1',
            rightHandMiddle2: 'mixamorigRightHandMiddle2',
            rightHandMiddle3: 'mixamorigRightHandMiddle3',
            rightHandRing1: 'mixamorigRightHandRing1',
            rightHandRing2: 'mixamorigRightHandRing2',
            rightHandRing3: 'mixamorigRightHandRing3',
            rightHandPinky1: 'mixamorigRightHandPinky1',
            rightHandPinky2: 'mixamorigRightHandPinky2',
            rightHandPinky3: 'mixamorigRightHandPinky3'
          };
          
          // IK config (from body.html)
          this.config = {
            shoulderWidth: 0.34,
            shoulderForward: 0.08,
            upperArmLength: 0.31,  // Increased to 31cm (was 0.25, +6cm total)
            lowerArmLength: 0.31   // Increased to 31cm (was 0.25, +6cm total)
          };
          
          // Smoothing
          this.torsoRotation = new THREE.Quaternion();
          this.bodyTilt = new THREE.Quaternion();
          this.smoothingFactor = 0.15;
          this.mirrorDistance = 2.0;
          this.manualRotationY = 0; // Set by vr-locomotion
          
          // Breathing animation
          this.breathingPhase = 0; // Current phase of breathing cycle (0 to 2*PI)
          this.breathingRate = 0.25; // Breaths per second (15 breaths/min)
          this.breathingAmount = 0.015; // Chest expansion amount (1.5cm)
          
          // Body dynamics for natural movement
          this.previousHeadPos = new THREE.Vector3();
          this.previousHeadPosInitialized = false;
          this.headVelocity = new THREE.Vector3();
          this.torsoLean = new THREE.Vector3(); // Current torso lean (smoothed)
          this.torsoLeanVelocity = 0.15; // How fast torso reacts to movement
          
          // Finger curl smoothing (for smooth finger animations)
          this.targetCurls = {
            left: { thumb: 0, index: 0, middle: 0, ring: 0, pinky: 0 },
            right: { thumb: 0, index: 0, middle: 0, ring: 0, pinky: 0 }
          };
          this.currentCurls = {
            left: { thumb: 0, index: 0, middle: 0, ring: 0, pinky: 0 },
            right: { thumb: 0, index: 0, middle: 0, ring: 0, pinky: 0 }
          };
          this.fingerSmoothingFactor = 0.3; // How fast fingers move (0-1, higher = faster)
          
          // Enable local clipping in renderer
          this.el.sceneEl.addEventListener('loaded', () => {
            const renderer = this.el.sceneEl.renderer;
            if (renderer) {
              renderer.localClippingEnabled = true;
            }
          });
          
          // Load model
          const loader = new THREE.FBXLoader();
          loader.load(
            this.data.modelPath,
            (fbx) => this.onModelLoaded(fbx),
            undefined,
            (error) => console.error('[Mixamo Body] Load error:', error)
          );
        },

        onModelLoaded: function(fbx) {
          this.modelLoaded = true;
          this.model = fbx;
          
          // Mixamo models export at 100x scale, need 0.01 to get to meters
          fbx.scale.set(0.01, 0.01, 0.01);
          
          // Mixamo models in T-pose face +Z, rotate 180¬∞ to face -Z (forward)
          fbx.rotation.y = Math.PI;
          
          this.el.object3D.add(fbx);
          
          // Find skeleton and set up materials
          const allMaterials = [];
          fbx.traverse((node) => {
            if (node.isSkinnedMesh && node.skeleton) {
              this.skeleton = node.skeleton;
              this.mapBones();
              this.skinnedMesh = node;
              
              // Clone material so each body has its own
              node.material = node.material.clone();
              allMaterials.push(node.material);
              
              console.log('[Mixamo Body] Found mesh with material:', node.material.type, 'Color:', node.material.color);
            }
            
            // Also check for regular meshes
            if (node.isMesh && !node.isSkinnedMesh) {
              node.material = node.material.clone();
              allMaterials.push(node.material);
              console.log('[Mixamo Body] Found regular mesh with material:', node.material.type);
            }
          });
          
          console.log('[Mixamo Body]', this.data.isMirror ? 'Mirror' : 'Local', '- Found', allMaterials.length, 'materials');
        },

        mapBones: function() {
          // Store initial T-pose rotations for reference
          this.initialBoneRotations = {};
          this.loggedHandTPose = false;
          this.legBones = []; // Store leg bones to hide them
          
          this.skeleton.bones.forEach((bone) => {
            const name = bone.name;
            
            // Store initial rotation for all bones
            this.initialBoneRotations[name] = bone.quaternion.clone();
            
            // Identify and store leg bones to hide them
            const lowerName = name.toLowerCase();
            if (lowerName.includes('leg') || lowerName.includes('upleg') || 
                lowerName.includes('foot') || lowerName.includes('toe')) {
              this.legBones.push(bone);
              // Scale leg bones to zero to hide them
              bone.scale.set(0.001, 0.001, 0.001);
            }
            
            if (name === this.boneNames.hips) {
              this.bones.hips = bone;
            }
            else if (name === this.boneNames.spine) this.bones.spine = bone;
            else if (name === this.boneNames.spine1) this.bones.spine1 = bone;
            else if (name === this.boneNames.spine2) this.bones.spine2 = bone;
            else if (name === this.boneNames.neck) this.bones.neck = bone;
            else if (name === this.boneNames.head) {
              this.bones.head = bone;
              // Scale head bone to hide it for local body only
              if (!this.data.isMirror) {
                bone.scale.set(0.001, 0.001, 0.001);
              }
            }
            else if (name === this.boneNames.leftShoulder) this.bones.leftShoulder = bone;
            else if (name === this.boneNames.leftArm) this.bones.leftUpperArm = bone;
            else if (name === this.boneNames.leftForeArm) this.bones.leftForearm = bone;
            else if (name === this.boneNames.leftHand) {
              this.bones.leftHandBone = bone;
              console.log('[T-Pose] Left Hand initial quat:', bone.quaternion.toArray());
            }
            // Left finger bones
            else if (name === this.boneNames.leftHandThumb1) this.bones.leftHandThumb1 = bone;
            else if (name === this.boneNames.leftHandThumb2) this.bones.leftHandThumb2 = bone;
            else if (name === this.boneNames.leftHandThumb3) this.bones.leftHandThumb3 = bone;
            else if (name === this.boneNames.leftHandIndex1) this.bones.leftHandIndex1 = bone;
            else if (name === this.boneNames.leftHandIndex2) this.bones.leftHandIndex2 = bone;
            else if (name === this.boneNames.leftHandIndex3) this.bones.leftHandIndex3 = bone;
            else if (name === this.boneNames.leftHandMiddle1) this.bones.leftHandMiddle1 = bone;
            else if (name === this.boneNames.leftHandMiddle2) this.bones.leftHandMiddle2 = bone;
            else if (name === this.boneNames.leftHandMiddle3) this.bones.leftHandMiddle3 = bone;
            else if (name === this.boneNames.leftHandRing1) this.bones.leftHandRing1 = bone;
            else if (name === this.boneNames.leftHandRing2) this.bones.leftHandRing2 = bone;
            else if (name === this.boneNames.leftHandRing3) this.bones.leftHandRing3 = bone;
            else if (name === this.boneNames.leftHandPinky1) this.bones.leftHandPinky1 = bone;
            else if (name === this.boneNames.leftHandPinky2) this.bones.leftHandPinky2 = bone;
            else if (name === this.boneNames.leftHandPinky3) this.bones.leftHandPinky3 = bone;
            else if (name === this.boneNames.rightShoulder) this.bones.rightShoulder = bone;
            else if (name === this.boneNames.rightArm) this.bones.rightUpperArm = bone;
            else if (name === this.boneNames.rightForeArm) this.bones.rightForearm = bone;
            else if (name === this.boneNames.rightHand) {
              this.bones.rightHandBone = bone;
              console.log('[T-Pose] Right Hand initial quat:', bone.quaternion.toArray());
            }
            // Right finger bones
            else if (name === this.boneNames.rightHandThumb1) this.bones.rightHandThumb1 = bone;
            else if (name === this.boneNames.rightHandThumb2) this.bones.rightHandThumb2 = bone;
            else if (name === this.boneNames.rightHandThumb3) this.bones.rightHandThumb3 = bone;
            else if (name === this.boneNames.rightHandIndex1) this.bones.rightHandIndex1 = bone;
            else if (name === this.boneNames.rightHandIndex2) this.bones.rightHandIndex2 = bone;
            else if (name === this.boneNames.rightHandIndex3) this.bones.rightHandIndex3 = bone;
            else if (name === this.boneNames.rightHandMiddle1) this.bones.rightHandMiddle1 = bone;
            else if (name === this.boneNames.rightHandMiddle2) this.bones.rightHandMiddle2 = bone;
            else if (name === this.boneNames.rightHandMiddle3) this.bones.rightHandMiddle3 = bone;
            else if (name === this.boneNames.rightHandRing1) this.bones.rightHandRing1 = bone;
            else if (name === this.boneNames.rightHandRing2) this.bones.rightHandRing2 = bone;
            else if (name === this.boneNames.rightHandRing3) this.bones.rightHandRing3 = bone;
            else if (name === this.boneNames.rightHandPinky1) this.bones.rightHandPinky1 = bone;
            else if (name === this.boneNames.rightHandPinky2) this.bones.rightHandPinky2 = bone;
            else if (name === this.boneNames.rightHandPinky3) this.bones.rightHandPinky3 = bone;
          });
        },

        tick: function(time, deltaTime) {
          if (!this.modelLoaded || !this.skeleton) return;
          if (!this.camera || !this.leftController || !this.rightController) return;
          
          const dt = Math.min(deltaTime / 1000, 0.1);
          
          // Update breathing animation phase
          this.breathingPhase += dt * this.breathingRate * Math.PI * 2;
          if (this.breathingPhase > Math.PI * 2) {
            this.breathingPhase -= Math.PI * 2;
          }
          
          if (this.data.isMirror) {
            this.updateMirrorBody(dt);
          } else {
            this.updateLocalBody(dt);
          }
          
          // Update finger poses from hand tracking
          this.updateFingerPoses();
        },

        updateLocalBody: function(dt) {
          // Get world positions (from body.html lines 1351-1356)
          const headWorldPos = new THREE.Vector3();
          const headWorldQuat = new THREE.Quaternion();
          const leftHandWorldPos = new THREE.Vector3();
          const leftHandWorldQuat = new THREE.Quaternion();
          const rightHandWorldPos = new THREE.Vector3();
          const rightHandWorldQuat = new THREE.Quaternion();
          
          this.camera.object3D.getWorldPosition(headWorldPos);
          this.camera.object3D.getWorldQuaternion(headWorldQuat);
          this.leftController.object3D.getWorldPosition(leftHandWorldPos);
          this.leftController.object3D.getWorldQuaternion(leftHandWorldQuat);
          this.rightController.object3D.getWorldPosition(rightHandWorldPos);
          this.rightController.object3D.getWorldQuaternion(rightHandWorldQuat);
          
          // Calculate head velocity for dynamic body movement
          if (this.previousHeadPosInitialized) {
            this.headVelocity.copy(headWorldPos).sub(this.previousHeadPos).divideScalar(dt);
          } else {
            this.previousHeadPosInitialized = true;
          }
          this.previousHeadPos.copy(headWorldPos);
          
          // Calculate torso orientation
          this.calculateTorsoOrientation(headWorldPos, headWorldQuat, leftHandWorldPos, rightHandWorldPos, dt);
          this.calculateBodyTilt(headWorldPos, leftHandWorldPos, rightHandWorldPos, dt);
          
          // Position body so HIPS are at correct height
          // Hips should be ~1.0m below head (or headY - 0.65 to keep feet on ground)
          // Model's hips bone is at Y=1.0m in local space
          // So entity Y position should be: (desired hips Y) - (model hips local Y)
          const desiredHipsY = headWorldPos.y - 0.65; // Hips 0.65m below head (lowered by 5cm)
          const modelHipsLocalY = 1.0; // From FBX: 99.79cm ‚âà 1.0m after scaling
          const bodyY = desiredHipsY - modelHipsLocalY; // Entity position
          
          // Apply 15cm backward offset in the body's local space (so it rotates with the body)
          const backwardOffset = new THREE.Vector3(0, 0, 0.15);
          backwardOffset.applyQuaternion(this.torsoRotation);
          
          this.el.object3D.position.set(
            headWorldPos.x + backwardOffset.x, 
            bodyY, 
            headWorldPos.z + backwardOffset.z
          );
          
          // Apply rotation
          const combinedRotation = new THREE.Quaternion()
            .copy(this.torsoRotation)
            .multiply(this.bodyTilt);
          this.el.object3D.quaternion.copy(combinedRotation);
          
          // Update bones
          this.updateBones(headWorldPos, headWorldQuat, leftHandWorldPos, rightHandWorldPos, leftHandWorldQuat, rightHandWorldQuat);
        },

        updateMirrorBody: function(dt) {
          // Get player positions (from body.html lines 1836-1849)
          const headWorldPos = new THREE.Vector3();
          const headWorldQuat = new THREE.Quaternion();
          const leftHandWorldPos = new THREE.Vector3();
          const leftHandWorldQuat = new THREE.Quaternion();
          const rightHandWorldPos = new THREE.Vector3();
          const rightHandWorldQuat = new THREE.Quaternion();
          
          this.camera.object3D.getWorldPosition(headWorldPos);
          this.camera.object3D.getWorldQuaternion(headWorldQuat);
          this.leftController.object3D.getWorldPosition(leftHandWorldPos);
          this.leftController.object3D.getWorldQuaternion(leftHandWorldQuat);
          this.rightController.object3D.getWorldPosition(rightHandWorldPos);
          this.rightController.object3D.getWorldQuaternion(rightHandWorldQuat);
          
          // Calculate head velocity for dynamic body movement (same as local body)
          if (this.previousHeadPosInitialized) {
            this.headVelocity.copy(headWorldPos).sub(this.previousHeadPos).divideScalar(dt);
          } else {
            this.previousHeadPosInitialized = true;
          }
          this.previousHeadPos.copy(headWorldPos);
          
          // Mirror center point (from body.html line 1852)
          const mirrorCenter = new THREE.Vector3(headWorldPos.x, headWorldPos.y - 0.3, headWorldPos.z - this.mirrorDistance);
          
          // Apply offset (from body.html lines 1855-1858)
          const offset = new THREE.Vector3(0, 0, -this.mirrorDistance);
          let mirrorHeadPos = headWorldPos.clone().add(offset);
          let mirrorLeftHandPos = leftHandWorldPos.clone().add(offset);
          let mirrorRightHandPos = rightHandWorldPos.clone().add(offset);
          
          // Apply manual rotation (from body.html lines 1861-1884)
          if (this.manualRotationY !== 0) {
            const rotationMatrix = new THREE.Matrix4().makeRotationY(this.manualRotationY);
            
            mirrorHeadPos.sub(mirrorCenter);
            mirrorHeadPos.applyMatrix4(rotationMatrix);
            mirrorHeadPos.add(mirrorCenter);
            
            mirrorLeftHandPos.sub(mirrorCenter);
            mirrorLeftHandPos.applyMatrix4(rotationMatrix);
            mirrorLeftHandPos.add(mirrorCenter);
            
            mirrorRightHandPos.sub(mirrorCenter);
            mirrorRightHandPos.applyMatrix4(rotationMatrix);
            mirrorRightHandPos.add(mirrorCenter);
            
            const manualQuat = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(0, 1, 0), this.manualRotationY);
            headWorldQuat.premultiply(manualQuat);
            leftHandWorldQuat.premultiply(manualQuat);
            rightHandWorldQuat.premultiply(manualQuat);
          }
          
          // Calculate torso orientation
          this.calculateTorsoOrientation(mirrorHeadPos, headWorldQuat, mirrorLeftHandPos, mirrorRightHandPos, dt);
          this.calculateBodyTilt(mirrorHeadPos, mirrorLeftHandPos, mirrorRightHandPos, dt);
          
          // Position body so hips are at correct height
          const desiredHipsY = mirrorHeadPos.y - 0.65; // Lowered by 5cm (was 0.6)
          const modelHipsLocalY = 1.0;
          const torsoY = desiredHipsY - modelHipsLocalY;
          
          // Apply 15cm backward offset in the body's local space (so it rotates with the body)
          const backwardOffset = new THREE.Vector3(0, 0, 0.15);
          backwardOffset.applyQuaternion(this.torsoRotation);
          
          this.el.object3D.position.set(
            mirrorHeadPos.x + backwardOffset.x, 
            torsoY, 
            mirrorHeadPos.z + backwardOffset.z
          );
          
          // Apply rotation
          const combinedRotation = new THREE.Quaternion()
            .copy(this.torsoRotation)
            .multiply(this.bodyTilt);
          this.el.object3D.quaternion.copy(combinedRotation);
          
          // Update bones
          this.updateBones(mirrorHeadPos, headWorldQuat, mirrorLeftHandPos, mirrorRightHandPos, leftHandWorldQuat, rightHandWorldQuat);
        },

        calculateTorsoOrientation: function(headPos, headQuat, leftHandPos, rightHandPos, dt) {
          // Simplified from body.html lines 1407-1486
          const headForwardFlat = new THREE.Vector3(0, 0, -1).applyQuaternion(headQuat);
          headForwardFlat.y = 0;
          headForwardFlat.normalize();
          
          const shoulderLine = rightHandPos.clone().sub(leftHandPos);
          shoulderLine.y = 0;
          const shoulderDist = shoulderLine.length();
          shoulderLine.normalize();
          
          const controllerForward = new THREE.Vector3().crossVectors(shoulderLine, new THREE.Vector3(0, 1, 0));
          controllerForward.normalize();
          
          if (controllerForward.dot(headForwardFlat) < 0) {
            controllerForward.negate();
          }
          
          // Weight adjustment based on hand distance
          let controllerWeight = 0.8;
          if (shoulderDist < 0.25) {
            controllerWeight = 0.3;
          } else if (shoulderDist > 0.35) {
            controllerWeight = 1.0;
          }
          
          const blendedForward = new THREE.Vector3()
            .addScaledVector(controllerForward, controllerWeight)
            .addScaledVector(headForwardFlat, 1.0 - controllerWeight)
            .normalize();
          
          const targetRotation = new THREE.Quaternion().setFromUnitVectors(
            new THREE.Vector3(0, 0, -1),
            blendedForward
          );
          
          this.torsoRotation.slerp(targetRotation, this.smoothingFactor);
        },

        calculateBodyTilt: function(headPos, leftHandPos, rightHandPos, dt) {
          // Disabled body tilt at entity level to prevent body movement
          // Spine bending is now handled entirely through individual spine bones
          this.bodyTilt.identity();
        },

        updateBones: function(headPos, headQuat, leftHandPos, rightHandPos, leftHandQuat, rightHandQuat) {
          // Reset bones to T-pose
          if (this.bones.hips) this.bones.hips.quaternion.identity();
          if (this.bones.spine) this.bones.spine.quaternion.identity();
          if (this.bones.spine1) this.bones.spine1.quaternion.identity();
          if (this.bones.spine2) this.bones.spine2.quaternion.identity();
          
          // SPINE BENDING: Combine hand-based lean with dynamic movement lean
          const bodyCenter = headPos.clone();
          bodyCenter.y -= 0.5;
          
          const leftRelative = leftHandPos.clone().sub(bodyCenter);
          const rightRelative = rightHandPos.clone().sub(bodyCenter);
          const avgHandPos = new THREE.Vector3()
            .addVectors(leftRelative, rightRelative)
            .multiplyScalar(0.5);
          
          // Convert to body-local space
          const invTorsoRot = this.torsoRotation.clone().invert();
          avgHandPos.applyQuaternion(invTorsoRot);
          
          // Hand-based lean (subtle, only at extreme reaches)
          const handForwardLean = Math.max(-0.08, Math.min(0.05, -avgHandPos.z * 0.08));
          const handSideLean = Math.max(-0.08, Math.min(0.08, avgHandPos.x * 0.1));
          
          // DYNAMIC MOVEMENT LEAN: Convert head velocity to body-local space
          const localVelocity = this.headVelocity.clone();
          localVelocity.applyQuaternion(invTorsoRot);
          
          // Calculate target lean based on velocity (opposite direction of movement)
          // When moving forward, lean back slightly; when moving sideways, lean opposite
          // Moderate sensitivity for natural movement
          const targetLean = new THREE.Vector3(
            localVelocity.z * 0.8,   // Forward/backward movement -> X rotation
            0,
            -localVelocity.x * 0.5   // Sideways movement -> Z rotation (reduced for less extreme lean)
          );
          
          // Smooth the torso lean toward target
          this.torsoLean.lerp(targetLean, this.torsoLeanVelocity);
          
          // Combine all lean sources
          const totalForwardLean = handForwardLean + this.torsoLean.x;
          const totalSideLean = handSideLean + this.torsoLean.z;
          
          // Calculate breathing animation (chest expansion)
          const breathingExpansion = Math.sin(this.breathingPhase) * this.breathingAmount;
          
          // Distribute rotation across spine segments
          if (this.bones.spine || this.bones.spine1 || this.bones.spine2) {
            // Each segment gets a portion of the total lean
            const spineRotations = [
              { bone: this.bones.spine, amount: 0.25, breathingAmount: 0.3 },
              { bone: this.bones.spine1, amount: 0.35, breathingAmount: 0.4 },
              { bone: this.bones.spine2, amount: 0.4, breathingAmount: 0.3 }
            ];
            
            spineRotations.forEach(({ bone, amount, breathingAmount }) => {
              if (bone) {
                // Add breathing to forward lean (negative X is backward arch)
                const breathingLean = -breathingExpansion * breathingAmount;
                
                const euler = new THREE.Euler(
                  -totalForwardLean * amount + breathingLean, // X-axis (flip for model rotation) + breathing
                  0,
                  -totalSideLean * amount,    // Z-axis (flip for model rotation)
                  'YXZ'
                );
                bone.quaternion.setFromEuler(euler);
              }
            });
          }
          
          // Head rotation (relative to body)
          // Model is rotated 180¬∞ at fbx level, which affects bone rotations
          if (this.bones.neck) {
            // Get relative head rotation (head relative to torso)
            const relativeHeadQuat = headQuat.clone();
            const invBodyQuat = this.torsoRotation.clone().invert();
            relativeHeadQuat.premultiply(invBodyQuat);
            
            // Model is rotated 180¬∞ around Y, which inverts X and Z rotations
            // Extract euler, flip X and Z, then rebuild quaternion
            const euler = new THREE.Euler().setFromQuaternion(relativeHeadQuat, 'YXZ');
            euler.x = -euler.x; // Flip pitch (nod)
            euler.z = -euler.z; // Flip roll (tilt)
            // Y (yaw/turn) stays the same
            
            const correctedQuat = new THREE.Quaternion().setFromEuler(euler);
            this.bones.neck.quaternion.copy(correctedQuat);
          }
          
          // Arms (with forearm twist)
          this.solveArmIK('left', leftHandPos, leftHandQuat);
          this.solveArmIK('right', rightHandPos, rightHandQuat);
        },
        
        updateFingerPoses: function() {
          // Get gamepad data (Quest-compatible syntax)
          const leftController = this.leftController.components['tracked-controls'];
          const rightController = this.rightController.components['tracked-controls'];
          const leftGamepad = leftController && leftController.controller && leftController.controller.gamepad;
          const rightGamepad = rightController && rightController.controller && rightController.controller.gamepad;
          
          if (!this.fingerDebugLogged) {
            console.log('[Finger Tracking] Left gamepad buttons:', leftGamepad && leftGamepad.buttons && leftGamepad.buttons.length);
            if (leftGamepad && leftGamepad.buttons) {
              console.log('[Finger Tracking] Button details:');
              leftGamepad.buttons.forEach((btn, i) => {
                if (btn.touched || btn.pressed) {
                  console.log(`  Button ${i}: pressed=${btn.pressed}, touched=${btn.touched}, value=${btn.value}`);
                }
              });
              console.log('[Finger Tracking] Touch any button/surface and check console to see which index it is');
            }
            this.fingerDebugLogged = true;
          }
          
          // Update target curls for LEFT hand
          if (leftGamepad && leftGamepad.buttons) {
            const trigger = (leftGamepad.buttons[0] && leftGamepad.buttons[0].value) || 0; // Trigger - index finger
            const grip = (leftGamepad.buttons[1] && leftGamepad.buttons[1].value) || 0;    // Grip - middle/ring/pinky
            
            // Thumb curls when touching ANY touch-sensitive surface:
            // Button 2: Often grip button or touchpad
            // Button 3: Thumbstick
            // Button 4: A/X button (face button lower)
            // Button 5: B/Y button (face button upper)
            // Button 6: Sometimes touchpad or additional surface
            let anyThumbTouch = 0;
            for (let i = 2; i <= 6; i++) {
              if (leftGamepad.buttons[i] && leftGamepad.buttons[i].touched) {
                anyThumbTouch = 1;
                break;
              }
            }
            
            this.updateTargetCurls('left', trigger, grip, anyThumbTouch);
          }
          
          // Update target curls for RIGHT hand
          if (rightGamepad && rightGamepad.buttons) {
            const trigger = (rightGamepad.buttons[0] && rightGamepad.buttons[0].value) || 0;
            const grip = (rightGamepad.buttons[1] && rightGamepad.buttons[1].value) || 0;
            
            let anyThumbTouch = 0;
            for (let i = 2; i <= 6; i++) {
              if (rightGamepad.buttons[i] && rightGamepad.buttons[i].touched) {
                anyThumbTouch = 1;
                break;
              }
            }
            
            this.updateTargetCurls('right', trigger, grip, anyThumbTouch);
          }
          
          // Smooth interpolation toward target curls
          ['left', 'right'].forEach(hand => {
            ['thumb', 'index', 'middle', 'ring', 'pinky'].forEach(finger => {
              const current = this.currentCurls[hand][finger];
              const target = this.targetCurls[hand][finger];
              this.currentCurls[hand][finger] = current + (target - current) * this.fingerSmoothingFactor;
            });
          });
          
          // Apply the smoothed curls to bones
          this.applyFingerCurls('left', this.currentCurls.left);
          this.applyFingerCurls('right', this.currentCurls.right);
        },
        
        updateTargetCurls: function(hand, trigger, grip, thumbTouch) {
          // Natural resting pose: fingers have slight curl (0.15-0.25)
          // This makes the hand look relaxed rather than stiff/straight
          const restingCurls = {
            thumb: 0.1,    // Thumb slightly relaxed
            index: 0.15,   // Index finger slightly curved
            middle: 0.2,   // Middle finger more curved
            ring: 0.25,    // Ring finger even more curved
            pinky: 0.25    // Pinky most curved (natural hand pose)
          };
          
          // Calculate active curl values
          const activeCurls = {
            thumb: thumbTouch * 0.8,  // Thumb curls when touching buttons
            index: trigger,            // Index follows trigger only
            middle: grip * 1.1,        // Middle curls slightly more than input
            ring: grip * 1.15,         // Ring curls more (natural grip)
            pinky: grip * 1.2          // Pinky curls most (anatomically correct)
          };
          
          // When gripping without trigger, keep index straighter
          // This prevents index from curling too much when only grip is pressed
          if (grip > 0.1 && trigger < 0.1) {
            activeCurls.index = 0; // Index stays straight when gripping without trigger
          }
          
          // Combine resting pose with active input (use the greater value)
          const curls = {
            thumb: Math.max(restingCurls.thumb, activeCurls.thumb),
            index: Math.max(restingCurls.index, activeCurls.index),
            middle: Math.max(restingCurls.middle, activeCurls.middle),
            ring: Math.max(restingCurls.ring, activeCurls.ring),
            pinky: Math.max(restingCurls.pinky, activeCurls.pinky)
          };
          
          // Override index finger when gripping without trigger - make it straighter than resting
          if (grip > 0.1 && trigger < 0.1) {
            curls.index = 0.05; // Very slight curl, straighter than resting pose
          };
          
          // Special case: "Thumbs up" gesture when grip is pressed but thumb is not on buttons
          if (grip > 0.5 && thumbTouch < 0.5) {
            curls.thumb = -0.15; // Extend thumb upward slightly (overrides resting pose, more natural)
          }
          
          this.targetCurls[hand] = curls;
        },
        
        applyFingerCurls: function(hand, curls) {
          // Apply curl values to finger bones
          const fingerBones = {
            thumb: hand === 'left' ? [this.bones.leftHandThumb1, this.bones.leftHandThumb2, this.bones.leftHandThumb3] : 
                                     [this.bones.rightHandThumb1, this.bones.rightHandThumb2, this.bones.rightHandThumb3],
            index: hand === 'left' ? [this.bones.leftHandIndex1, this.bones.leftHandIndex2, this.bones.leftHandIndex3] :
                                     [this.bones.rightHandIndex1, this.bones.rightHandIndex2, this.bones.rightHandIndex3],
            middle: hand === 'left' ? [this.bones.leftHandMiddle1, this.bones.leftHandMiddle2, this.bones.leftHandMiddle3] :
                                      [this.bones.rightHandMiddle1, this.bones.rightHandMiddle2, this.bones.rightHandMiddle3],
            ring: hand === 'left' ? [this.bones.leftHandRing1, this.bones.leftHandRing2, this.bones.leftHandRing3] :
                                    [this.bones.rightHandRing1, this.bones.rightHandRing2, this.bones.rightHandRing3],
            pinky: hand === 'left' ? [this.bones.leftHandPinky1, this.bones.leftHandPinky2, this.bones.leftHandPinky3] :
                                     [this.bones.rightHandPinky1, this.bones.rightHandPinky2, this.bones.rightHandPinky3]
          };
          
          // Apply curls to finger bones
          Object.keys(fingerBones).forEach(fingerName => {
            const bones = fingerBones[fingerName];
            const curl = curls[fingerName];
            
            // Thumb uses different axis/sign than other fingers
            const isThumb = fingerName === 'thumb';
            const axis = isThumb ? new THREE.Vector3(0, 0, 1) : new THREE.Vector3(1, 0, 0);
            // Left hand: fingers=1, thumb=-1
            // Right hand: fingers=1 (same as left), thumb=1
            const sign = isThumb ? (hand === 'left' ? -1 : 1) : 1;
            
            bones.forEach((bone, i) => {
              if (!bone) return;
              
              // Reset to T-pose first
              const initialRot = this.initialBoneRotations[bone.name];
              if (initialRot) {
                bone.quaternion.copy(initialRot);
              }
              
              // Apply curl rotation (more curl for distal bones)
              const curlAmount = curl * (0.5 + i * 0.25); // Progressive curl
              const curlAngle = curlAmount * Math.PI * 0.6 * sign; // curl angle
              
              const curlQuat = new THREE.Quaternion().setFromAxisAngle(axis, curlAngle);
              
              bone.quaternion.multiply(curlQuat);
            });
          });
        },

        solveArmIK: function(hand, handWorldPos, handWorldQuat) {
          const shoulderBone = this.bones[`${hand}Shoulder`];
          const upperArmBone = this.bones[`${hand}UpperArm`];
          const forearmBone = this.bones[`${hand}Forearm`];
          const handBone = this.bones[`${hand}HandBone`];
          
          if (!shoulderBone || !upperArmBone || !forearmBone) {
            return;
          }
          
          // Get actual shoulder bone world position (not calculated, but from the skeleton)
          const shoulderWorldPos = new THREE.Vector3();
          shoulderBone.getWorldPosition(shoulderWorldPos);
          
          // Adjust hand position to account for hand bone offset in the skeleton
          // The VR controllers are positioned differently than the hand bones
          const adjustedHandPos = handWorldPos.clone();
          
          // Add the left/right offset correction IN BODY LOCAL SPACE
          // This ensures the offset is correct even when the body is rotated (mirror body)
          const leftRightOffsetLocal = new THREE.Vector3(hand === 'left' ? 0.1 : -0.1, 0, 0);
          const leftRightOffsetWorld = leftRightOffsetLocal.applyQuaternion(this.el.object3D.quaternion);
          adjustedHandPos.add(leftRightOffsetWorld);
          
          // Two-bone IK (from body.html lines 1608-1627)
          const shoulderToHand = adjustedHandPos.clone().sub(shoulderWorldPos);
          const distance = shoulderToHand.length();
          const maxReach = (this.config.upperArmLength + this.config.lowerArmLength) * 0.999;
          const minReach = Math.abs(this.config.upperArmLength - this.config.lowerArmLength) * 1.001;
          
          let targetHandPos = adjustedHandPos.clone();
          if (distance > maxReach) {
            targetHandPos = shoulderWorldPos.clone().add(shoulderToHand.normalize().multiplyScalar(maxReach));
          } else if (distance < minReach) {
            targetHandPos = shoulderWorldPos.clone().add(shoulderToHand.normalize().multiplyScalar(minReach));
          }
          
          // Law of cosines (from body.html lines 1629-1641)
          const toTarget = targetHandPos.clone().sub(shoulderWorldPos);
          const targetDist = toTarget.length();
          const toTargetDir = toTarget.normalize();
          
          const upperSq = this.config.upperArmLength * this.config.upperArmLength;
          const lowerSq = this.config.lowerArmLength * this.config.lowerArmLength;
          const distSq = targetDist * targetDist;
          
          const cosAngle = (upperSq + distSq - lowerSq) / (2 * this.config.upperArmLength * targetDist);
          const clampedCos = Math.max(-0.999, Math.min(0.999, cosAngle));
          const angle = Math.acos(clampedCos);
          
          // Elbow bend direction - Enhanced with hand orientation influence
          const bodyForward = new THREE.Vector3(0, 0, -1).applyQuaternion(this.torsoRotation);
          const bodyRight = new THREE.Vector3(1, 0, 0).applyQuaternion(this.torsoRotation);
          const bodyOutward = bodyRight.clone().multiplyScalar(hand === 'left' ? -1 : 1);
          
          // Base bend direction: outward and down
          let bendDir = new THREE.Vector3()
            .addScaledVector(bodyOutward, 0.4)
            .addScaledVector(new THREE.Vector3(0, -1, 0), 0.4)
            .normalize();
          
          // IMPROVED ELBOW ORIENTATION: Adjust bend direction based on hand rotation
          // Extract the "palm down" vector from hand orientation
          const handUp = new THREE.Vector3(0, 1, 0).applyQuaternion(handWorldQuat);
          const handForward = new THREE.Vector3(0, 0, -1).applyQuaternion(handWorldQuat);
          
          // Blend hand's up vector into bend direction (palms facing inward = elbows out)
          // This makes the elbow naturally follow wrist rotation
          bendDir.addScaledVector(handUp, 0.3);
          bendDir.normalize();
          
          // Make bend perpendicular to shoulder-hand direction
          bendDir.addScaledVector(toTargetDir, -bendDir.dot(toTargetDir)).normalize();
          
          // Calculate elbow (from body.html lines 1667-1673)
          const elbowDir = new THREE.Vector3()
            .addScaledVector(toTargetDir, Math.cos(angle))
            .addScaledVector(bendDir, Math.sin(angle))
            .normalize();
          
          let elbowWorldPos = shoulderWorldPos.clone().add(elbowDir.multiplyScalar(this.config.upperArmLength));
          
          // Enforce exact lengths (from body.html lines 1676-1697)
          const shoulderToElbow = elbowWorldPos.clone().sub(shoulderWorldPos);
          if (Math.abs(shoulderToElbow.length() - this.config.upperArmLength) > 0.0001) {
            elbowWorldPos.copy(shoulderWorldPos).add(shoulderToElbow.normalize().multiplyScalar(this.config.upperArmLength));
          }
          
          const elbowToHand = targetHandPos.clone().sub(elbowWorldPos);
          if (Math.abs(elbowToHand.length() - this.config.lowerArmLength) > 0.0001) {
            targetHandPos.copy(elbowWorldPos).add(elbowToHand.normalize().multiplyScalar(this.config.lowerArmLength));
          }
          
          // Convert to bone rotations (local space)
          // The key insight: bones are hierarchical, we need to set rotations relative to PARENT bone
          this.el.object3D.updateMatrixWorld(true);
          
          // Upper Arm: rotate from shoulder to elbow
          upperArmBone.parent.updateMatrixWorld(true);
          
          // Get the direction in world space
          const upperArmWorldDir = elbowWorldPos.clone().sub(shoulderWorldPos).normalize();
          
          // Convert shoulder and elbow to parent bone's local space
          const shoulderInParent = upperArmBone.parent.worldToLocal(shoulderWorldPos.clone());
          const elbowInParent = upperArmBone.parent.worldToLocal(elbowWorldPos.clone());
          
          // Direction in parent's local space
          // Bone direction should point FROM parent (shoulder) TO child (elbow)
          // But we're getting inverted results, so flip the subtraction
          const upperArmParentDir = shoulderInParent.clone().sub(elbowInParent).normalize();
          
          // T-pose direction: Mixamo bones often use Y-down for limbs in T-pose
          // Try negative Y (pointing down)
          const tPoseDir = new THREE.Vector3(0, -1, 0);
          
          // Calculate rotation from T-pose to target direction
          const upperArmQuat = new THREE.Quaternion().setFromUnitVectors(tPoseDir, upperArmParentDir);
          
          upperArmBone.quaternion.copy(upperArmQuat);
          upperArmBone.updateMatrixWorld(true);
          
          // Forearm: rotate from elbow to hand
          forearmBone.parent.updateMatrixWorld(true);
          
          // Convert to parent (upperArm) local space
          const elbowInUpperArm = forearmBone.parent.worldToLocal(elbowWorldPos.clone());
          const handInUpperArm = forearmBone.parent.worldToLocal(targetHandPos.clone());
          
          // Direction in parent's local space (flipped like upper arm)
          const forearmParentDir = elbowInUpperArm.clone().sub(handInUpperArm).normalize();
          
          // Forearm also uses same T-pose direction
          const forearmQuat = new THREE.Quaternion().setFromUnitVectors(tPoseDir, forearmParentDir);
          
          // FOREARM TWIST: Add pronation/supination based on wrist rotation
          // Extract the twist component from hand rotation
          forearmBone.updateMatrixWorld(true);
          
          // Get hand rotation relative to forearm's natural alignment
          const forearmWorldQuat = new THREE.Quaternion();
          forearmBone.getWorldQuaternion(forearmWorldQuat);
          
          // Hand rotation relative to forearm
          const handRelativeForearm = handWorldQuat.clone();
          handRelativeForearm.premultiply(forearmWorldQuat.clone().invert());
          
          // Extract twist angle around forearm axis (Y-axis in local space)
          // This represents pronation (palm down) vs supination (palm up)
          const handEuler = new THREE.Euler().setFromQuaternion(handRelativeForearm, 'YXZ');
          const twistAngle = handEuler.y; // Y-axis rotation = twist
          
          // Apply 50% of the twist to the forearm (rest stays in hand)
          // This creates natural forearm rotation
          const forearmTwist = new THREE.Quaternion().setFromAxisAngle(
            new THREE.Vector3(0, 1, 0), // Local Y-axis (along forearm)
            twistAngle * 0.5 // 50% of hand twist
          );
          
          // Combine direction rotation with twist
          forearmBone.quaternion.copy(forearmQuat).multiply(forearmTwist);
          
          forearmBone.updateMatrixWorld(true);
          
          // Hand orientation
          if (handBone) {
            forearmBone.updateMatrixWorld(true);
            
            // Just use the controller's world quaternion directly, like we do for arms
            // Convert from world space to forearm's local space
            const forearmWorldQuat = new THREE.Quaternion();
            forearmBone.getWorldQuaternion(forearmWorldQuat);
            
            let handLocalQuat = handWorldQuat.clone();
            handLocalQuat.premultiply(forearmWorldQuat.clone().invert());
            
            // Apply 180¬∞ correction around X axis in LOCAL bone space to flip the hand direction
            // This accounts for the model's 180¬∞ rotation
            const localXFlip = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(1, 0, 0), Math.PI);
            handLocalQuat.multiply(localXFlip);
            
            // Add 90¬∞ roll correction (left clockwise = +90¬∞, right counterclockwise = -90¬∞)
            // Roll is around Y axis in local bone space (forearm direction)
            const rollCorrection = new THREE.Quaternion().setFromAxisAngle(
              new THREE.Vector3(0, 1, 0),
              hand === 'left' ? Math.PI / 2 : -Math.PI / 2
            );
            handLocalQuat.multiply(rollCorrection);
            
            handBone.quaternion.copy(handLocalQuat);
          }
        }
      });

      // Initialize app
      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', () => LanguageApp.init());
      } else {
        LanguageApp.init();
      }
    </script>
  </body>
</html>

